{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etniX_KTlJ5U"
   },
   "source": [
    "# USAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3jM0qLU8MgZ"
   },
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6u1DGKsAlLF-"
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from usad import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1crx5rGP9ONf"
   },
   "source": [
    "## EDA - Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfSj4FYL9W8Y"
   },
   "source": [
    "### Normal period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "XeDLxV_r1G9n",
    "outputId": "576538dd-64f2-46fa-8e6f-6c2ffdebad15"
   },
   "outputs": [],
   "source": [
    "data_path = \"C:\\\\Users\\\\PC\\\\OneDrive\\\\문서\\\\GitHub\\\\datasets\\\\\"\n",
    "\n",
    "#Read data\n",
    "#data1_1 = pd.read_csv(data_path + \"Bearing1_1.csv_wavelet_result.csv\", usecols=['cD3', 'cD3.1'])\n",
    "#data1_3 = pd.read_csv(data_path + \"Bearing1_3.csv_wavelet_result.csv\", usecols=['cD3', 'cD3.1'])\n",
    "\n",
    "data1_1 = pd.read_csv(data_path + \"Bearing1_1.csv\")\n",
    "data1_3 = pd.read_csv(data_path + \"Bearing1_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Horiz</th>\n",
       "      <th>Verti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.908484</td>\n",
       "      <td>1.458611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.651959</td>\n",
       "      <td>1.457905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.621243</td>\n",
       "      <td>1.364296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.602309</td>\n",
       "      <td>1.617538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.035000</td>\n",
       "      <td>1.228749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Horiz     Verti\n",
       "0  2.908484  1.458611\n",
       "1  2.651959  1.457905\n",
       "2  2.621243  1.364296\n",
       "3  2.602309  1.617538\n",
       "4  2.035000  1.228749"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2778, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxFNH5kU9hIE"
   },
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Mfxj4Uxn9kv4"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "x = data1_1.values\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "scaled_data = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "mQ6_U4jn9nlw",
    "outputId": "f1cc1bd6-f1cc-4764-b1cc-2fd989ac4918"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031524</td>\n",
       "      <td>0.018592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026699</td>\n",
       "      <td>0.018578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.031524  0.018592\n",
       "1  0.026699  0.018578"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXJi503b-j_d"
   },
   "source": [
    "### Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vyplttZa-BRN"
   },
   "outputs": [],
   "source": [
    "window_size=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dzGJMp6Y-BN5",
    "outputId": "2949d278-1313-442c-f06b-275a8c6c6578"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2766, 12, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows_normal=scaled_data.values[np.arange(window_size)[None, :] + np.arange(scaled_data.shape[0]-window_size)[:, None]]\n",
    "windows_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k70ZFxGs-_7m"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 100\n",
    "hidden_size = 10\n",
    "\n",
    "w_size=windows_normal.shape[1]*windows_normal.shape[2]\n",
    "z_size=windows_normal.shape[1]*hidden_size\n",
    "\n",
    "windows_normal_train = windows_normal[:400]\n",
    "windows_normal_test = windows_normal[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import math\n",
    "\n",
    "class Dataloader(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, shuffle=False):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle=shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    # batch 단위로 직접 묶어줘야 함\n",
    "    def __getitem__(self, idx):\n",
    "        # sampler의 역할(index를 batch_size만큼 sampling해줌)\n",
    "        indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "\n",
    "        batch_x = [self.x[i] for i in indices]\n",
    "        batch_y = [self.y[i] for i in indices]\n",
    "\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n",
    "    # epoch이 끝날때마다 실행\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.x))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_normal_train_re = windows_normal_train.reshape(windows_normal_train.shape[0], w_size)\n",
    "windows_normal_test_re = windows_normal_test.reshape(windows_normal_test.shape[0], w_size)\n",
    "windows_normal_re = windows_normal.reshape(windows_normal.shape[0], w_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Dataloader(windows_normal_train_re,windows_normal_train_re,BATCH_SIZE)\n",
    "test_loader = Dataloader(windows_normal_test_re,windows_normal_test_re,BATCH_SIZE)\n",
    "whole_loader = Dataloader(windows_normal_re,windows_normal_re,BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* USAD tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model) :\n",
    "    def __init__(self, in_size, latent_size):\n",
    "        super().__init__()\n",
    "        self.model = tf.keras.Sequential([\n",
    "            tf.keras.Input(shape = (in_size)),\n",
    "            tf.keras.layers.Dense(int(in_size/2), activation = \"relu\"),\n",
    "            tf.keras.layers.Dense(int(in_size/4), activation = \"relu\"),\n",
    "            tf.keras.layers.Dense(latent_size, activation = \"relu\")\n",
    "        ])\n",
    "    \n",
    "    def call(self, x) :\n",
    "        z = self.model(x)\n",
    "        return z\n",
    "    \n",
    "class Decoder(tf.keras.Model) :\n",
    "    def __init__(self, latent_size, out_size):\n",
    "        super().__init__()\n",
    "        self.model = tf.keras.Sequential([\n",
    "            tf.keras.Input(shape = (latent_size)),\n",
    "            tf.keras.layers.Dense(int(out_size/4), activation = \"relu\"),\n",
    "            tf.keras.layers.Dense(int(out_size/2), activation = \"relu\"),\n",
    "            tf.keras.layers.Dense(out_size, activation = \"sigmoid\")\n",
    "        ])\n",
    "    \n",
    "    def call(self, x) :\n",
    "        w = self.model(x)\n",
    "        return w\n",
    "    \n",
    "class UsadModel(tf.keras.Model):\n",
    "    def __init__(self, w_size, z_size, alpha = .5, beta = .5):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(w_size, z_size)\n",
    "        self.decoder1 = Decoder(z_size, w_size)\n",
    "        self.decoder2 = Decoder(z_size, w_size)\n",
    "        \n",
    "        self.latent_vector = self.encoder(self.encoder.model.inputs)\n",
    "        self.ae_output1 = self.decoder1(self.latent_vector)\n",
    "        self.ae_output2 = self.decoder2(self.latent_vector)\n",
    "\n",
    "        self.ae_model1 = tf.keras.Model(inputs = self.encoder.model.inputs, outputs = self.ae_output1)\n",
    "        self.ae_model2 = tf.keras.Model(inputs = self.encoder.model.inputs, outputs = self.ae_output2)\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        \n",
    "        self.alpha, self.beta = alpha, beta\n",
    "        \n",
    "    def evaluate(self, val_loader, n):\n",
    "        outputs = [self.validation_step(batch, n) for batch in val_loader]\n",
    "        return self.validation_epoch_end(outputs)\n",
    "    \n",
    "    def testing(self, test_loader):\n",
    "        results=[]\n",
    "        for batch, _ in test_loader:\n",
    "            w1=self.ae_model1(batch)\n",
    "            w2=self.ae_model2(w1)\n",
    "            results.append(self.alpha*np.mean((batch-w1).numpy()**2, axis = 1)+self.beta*np.mean((batch-w2).numpy()**2, axis = 1))\n",
    "        return results\n",
    "        \n",
    "    def call(self, x):\n",
    "        z = self.encoder(x)\n",
    "        w1 = self.decoder1(z)\n",
    "        w2 = self.decoder2(z)\n",
    "        w3 = self.decoder2(self.encoder(w1))\n",
    "        return w1, w2, w3\n",
    "    \n",
    "    def loss_fn(self, batch, n) :\n",
    "        loss1 = 1/n*tf.reduce_mean(tf.square(batch-self.w1)) + (1-1/n)*tf.reduce_mean(tf.square(batch-self.w3))\n",
    "        loss2 = 1/n*tf.reduce_mean(tf.square(batch-self.w2)) + (1-1/n)*tf.reduce_mean(tf.square(batch-self.w3))\n",
    "        \n",
    "        return loss1, loss2\n",
    "    \n",
    "    def training(self, train_loader, val_loader, num_epochs):\n",
    "        for n in range(num_epochs): \n",
    "            n += 1\n",
    "            \n",
    "            loss1_list, loss2_list = [], []\n",
    "            self.history = []\n",
    "            \n",
    "            # Iterate over the batches of a dataset.\n",
    "            for x_batch_train, y_batch_train in train_loader:\n",
    "                with tf.GradientTape() as ae1_tape, tf.GradientTape() as ae2_tape:\n",
    "                    self.z = self.encoder(x_batch_train)\n",
    "                    self.w1 = self.decoder1(self.z)\n",
    "                    self.w2 = self.decoder2(self.z)\n",
    "                    self.w3 = self.decoder2(self.encoder(self.w1))\n",
    "\n",
    "                    # Loss value for this minibatch\n",
    "                    loss1, loss2 = self.loss_fn(x_batch_train, n)\n",
    "                    \n",
    "                    # Add extra losses created during this forward pass:\n",
    "                    #loss_value += sum(model.losses)\n",
    "\n",
    "                grads_ae1 = ae1_tape.gradient(loss1, self.ae_model1.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads_ae1, self.ae_model1.trainable_weights))\n",
    "                grads_ae2 = ae2_tape.gradient(loss2, self.ae_model2.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads_ae2, self.ae_model2.trainable_weights))\n",
    "                loss1_list.append(loss1)\n",
    "                loss2_list.append(loss2)\n",
    "                \n",
    "            #print(\"Epoch [{}], train_loss1: {:.4f}, train_loss2: {:.4f}\".format(n, np.mean(loss1_list), np.mean(loss2_list)))\n",
    "            result = self.evaluate(val_loader, n)\n",
    "            self.epoch_end(n, result)\n",
    "            self.history.append(result)\n",
    "            \n",
    "    def validation_step(self, batch, n):\n",
    "        z = self.encoder(batch)\n",
    "        w1 = self.decoder1(z)\n",
    "        w2 = self.decoder2(z)\n",
    "        w3 = self.decoder2(self.encoder(w1))\n",
    "        loss1 = 1/n*tf.reduce_mean(tf.square(batch-w1)) + (1-1/n)*tf.reduce_mean(tf.square(batch-w3))\n",
    "        loss2 = 1/n*tf.reduce_mean(tf.square(batch-w2)) + (1-1/n)*tf.reduce_mean(tf.square(batch-w3))\n",
    "        \n",
    "        return {'val_loss1': loss1, 'val_loss2': loss2}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses1 = [x['val_loss1'] for x in outputs]\n",
    "        epoch_loss1 = tf.reduce_mean(batch_losses1)\n",
    "        batch_losses2 = [x['val_loss2'] for x in outputs]\n",
    "        epoch_loss2 = tf.reduce_mean(batch_losses2)\n",
    "        return {'val_loss1': epoch_loss1.numpy(), 'val_loss2': epoch_loss2.numpy()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss1: {:.4f}, val_loss2: {:.4f}\".format(epoch, result['val_loss1'], result['val_loss2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Encoder.call of <__main__.Encoder object at 0x00000204CBB0D588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Encoder.call of <__main__.Encoder object at 0x00000204CBB0D588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x00000204CBB55848>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x00000204CBB55848>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x00000204CBB4B6C8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x00000204CBB4B6C8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "Epoch [1], val_loss1: 0.2214, val_loss2: 0.2171\n",
      "Epoch [2], val_loss1: 0.1896, val_loss2: 0.1803\n",
      "Epoch [3], val_loss1: 0.1391, val_loss2: 0.1237\n",
      "Epoch [4], val_loss1: 0.0843, val_loss2: 0.0657\n",
      "Epoch [5], val_loss1: 0.0433, val_loss2: 0.0255\n",
      "Epoch [6], val_loss1: 0.0259, val_loss2: 0.0121\n",
      "Epoch [7], val_loss1: 0.0163, val_loss2: 0.0081\n",
      "Epoch [8], val_loss1: 0.0098, val_loss2: 0.0061\n",
      "Epoch [9], val_loss1: 0.0060, val_loss2: 0.0049\n",
      "Epoch [10], val_loss1: 0.0047, val_loss2: 0.0045\n",
      "Epoch [11], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [12], val_loss1: 0.0041, val_loss2: 0.0040\n",
      "Epoch [13], val_loss1: 0.0040, val_loss2: 0.0040\n",
      "Epoch [14], val_loss1: 0.0040, val_loss2: 0.0040\n",
      "Epoch [15], val_loss1: 0.0040, val_loss2: 0.0040\n",
      "Epoch [16], val_loss1: 0.0040, val_loss2: 0.0040\n",
      "Epoch [17], val_loss1: 0.0041, val_loss2: 0.0040\n",
      "Epoch [18], val_loss1: 0.0041, val_loss2: 0.0040\n",
      "Epoch [19], val_loss1: 0.0041, val_loss2: 0.0041\n",
      "Epoch [20], val_loss1: 0.0041, val_loss2: 0.0041\n",
      "Epoch [21], val_loss1: 0.0042, val_loss2: 0.0041\n",
      "Epoch [22], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [23], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [24], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [25], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [26], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [27], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [28], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [29], val_loss1: 0.0043, val_loss2: 0.0042\n",
      "Epoch [30], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [31], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [32], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [33], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [34], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [35], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [36], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [37], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [38], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [39], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [40], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [41], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [42], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [43], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [44], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [45], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [46], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [47], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [48], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [49], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [50], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [51], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [52], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [53], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [54], val_loss1: 0.0043, val_loss2: 0.0043\n",
      "Epoch [55], val_loss1: 0.0043, val_loss2: 0.0042\n",
      "Epoch [56], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [57], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [58], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [59], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [60], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [61], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [62], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [63], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [64], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [65], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [66], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [67], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [68], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [69], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [70], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [71], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [72], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [73], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [74], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [75], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [76], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [77], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [78], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [79], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [80], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [81], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [82], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [83], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [84], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [85], val_loss1: 0.0042, val_loss2: 0.0042\n",
      "Epoch [86], val_loss1: 0.0042, val_loss2: 0.0041\n",
      "Epoch [87], val_loss1: 0.0041, val_loss2: 0.0041\n",
      "Epoch [88], val_loss1: 0.0041, val_loss2: 0.0041\n",
      "Epoch [89], val_loss1: 0.0041, val_loss2: 0.0041\n",
      "Epoch [90], val_loss1: 0.0041, val_loss2: 0.0041\n",
      "Epoch [91], val_loss1: 0.0041, val_loss2: 0.0041\n",
      "Epoch [92], val_loss1: 0.0041, val_loss2: 0.0041\n",
      "Epoch [93], val_loss1: 0.0041, val_loss2: 0.0041\n",
      "Epoch [94], val_loss1: 0.0041, val_loss2: 0.0041\n",
      "Epoch [95], val_loss1: 0.0041, val_loss2: 0.0041\n",
      "Epoch [96], val_loss1: 0.0041, val_loss2: 0.0041\n",
      "Epoch [97], val_loss1: 0.0041, val_loss2: 0.0041\n",
      "Epoch [98], val_loss1: 0.0041, val_loss2: 0.0041\n",
      "Epoch [99], val_loss1: 0.0041, val_loss2: 0.0041\n",
      "Epoch [100], val_loss1: 0.0041, val_loss2: 0.0041\n"
     ]
    }
   ],
   "source": [
    "model_usad = UsadModel(w_size, z_size)\n",
    "model_usad.training(train_loader, test_loader, N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model_usad.testing(whole_loader)\n",
    "a = np.concatenate([np.stack(a[:-1]).flatten(), a[-1].flatten()])\n",
    "b = model_usad.testing(train_loader)\n",
    "b = np.concatenate([np.stack(b[:-1]).flatten(), b[-1].flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot([x for x in range(a.shape[0])], a)\n",
    "plt.axhline(y=b.mean() + 5 * b.std(), color='r', linewidth=1)\n",
    "plt.title('Anomaly Detection')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Anomaly Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00023435933144355658"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mean() + 5 * b.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1895"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx = np.max(np.where(a < b.mean() + 5 * b.std())[0]); start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(705,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ = a[:1895]\n",
    "np.where(a_ > b.mean() + 5 * b.std())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly gap maximize net\n",
    "\n",
    "* 제안 아이디어 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class UsadModel_AGM(tf.keras.Model):\n",
    "    def __init__(self, w_size, z_size, alpha = .5, beta = .5):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(w_size, z_size)\n",
    "        self.decoder1 = Decoder(z_size, w_size)\n",
    "        self.decoder2 = Decoder(z_size, w_size)\n",
    "        \n",
    "        self.latent_vector = self.encoder(self.encoder.model.inputs)\n",
    "        self.ae_output1 = self.decoder1(self.latent_vector)\n",
    "        self.ae_output2 = self.decoder2(self.latent_vector)\n",
    "\n",
    "        self.ae_model1 = tf.keras.Model(inputs = self.encoder.model.inputs, outputs = self.ae_output1)\n",
    "        self.ae_model2 = tf.keras.Model(inputs = self.encoder.model.inputs, outputs = self.ae_output2)\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        \n",
    "        self.alpha, self.beta = alpha, beta\n",
    "        \n",
    "    def evaluate(self, val_loader, n):\n",
    "        outputs = [self.validation_step(batch, n) for batch in val_loader]\n",
    "        return self.validation_epoch_end(outputs)\n",
    "\n",
    "    def testing(self, test_loader):\n",
    "        results=[]\n",
    "        for batch, _ in test_loader:\n",
    "            w1=self.ae_model1(batch)\n",
    "            w2=self.ae_model2(w1)\n",
    "            results.append(self.alpha*np.mean((batch-w1).numpy()**2, axis = 1)+self.beta*np.mean((batch-w2).numpy()**2, axis = 1))\n",
    "        return results\n",
    "        \n",
    "    def call(self, x):\n",
    "        z = self.encoder(x)\n",
    "        w1 = self.decoder1(z)\n",
    "        w2 = self.decoder2(z)\n",
    "        w3 = self.decoder2(self.encoder(w1))\n",
    "        return w1, w2, w3\n",
    "    \n",
    "    def loss_fn(self, batch, n) :\n",
    "        loss1 = 1/n*tf.reduce_mean(tf.square(batch-self.w1)) + (1-1/n)*tf.reduce_mean(tf.square(batch-self.w3))\n",
    "        loss2 = 1/n*tf.reduce_mean(tf.square(batch-self.w2)) + (1-1/n)*tf.reduce_mean(tf.square(batch-self.w3))\n",
    "        \n",
    "        return loss1, loss2\n",
    "    \n",
    "    def training(self, train_loader, val_loader, num_epochs):\n",
    "        self.history = []\n",
    "        \n",
    "        for n in range(num_epochs): \n",
    "            n += 1\n",
    "            \n",
    "            loss1_list, loss2_list, loss3_list = [], [], []\n",
    "            \n",
    "            # Iterate over the batches of a dataset.\n",
    "            for x_batch_train, y_batch_train in train_loader:\n",
    "                with tf.GradientTape() as ae1_tape, tf.GradientTape() as ae2_tape, tf.GradientTape() as pg_tape:\n",
    "                    self.z = self.encoder(x_batch_train)\n",
    "                    self.w1 = self.decoder1(self.z)\n",
    "                    self.w2 = self.decoder2(self.z)\n",
    "                    self.w3 = self.decoder2(self.encoder(self.w1))\n",
    "                    \n",
    "                    real_recon1 = x_batch_train-self.w1\n",
    "                    real_recon2 = x_batch_train-self.w2\n",
    "                    fake_recon = x_batch_train-self.w3\n",
    "\n",
    "                    # Loss value for this minibatch\n",
    "                    loss1, loss2 = self.loss_fn(x_batch_train, n)\n",
    "                    \n",
    "                    pg_advantage = tf.stop_gradient(tf.reduce_mean(tf.square(fake_recon))-tf.reduce_mean(tf.square(real_recon2)))\n",
    "                    loss3 = -tf.reduce_mean(tf.math.log(self.w3+1e-6) * pg_advantage)\n",
    "        \n",
    "                    \n",
    "                    # Add extra losses created during this forward pass:\n",
    "                    #loss_value += sum(model.losses)\n",
    "\n",
    "                grads_ae1 = ae1_tape.gradient(loss1, self.ae_model1.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads_ae1, self.ae_model1.trainable_weights))\n",
    "                grads_ae2 = ae2_tape.gradient(loss2, self.ae_model2.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads_ae2, self.ae_model2.trainable_weights))\n",
    "                grads_ae3 = pg_tape.gradient(loss3, self.ae_model2.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads_ae3, self.ae_model2.trainable_weights))\n",
    "                \n",
    "                loss1_list.append(loss1)\n",
    "                loss2_list.append(loss2)\n",
    "                loss3_list.append(loss3)\n",
    "                \n",
    "            result = self.evaluate(val_loader, n)\n",
    "            self.epoch_end(n, result)\n",
    "            self.history.append(result)\n",
    "                \n",
    "            #print(\"Epoch [{}], train_loss1: {:.4f}, train_loss2: {:.4f}, train_loss3: {:.4f}\".format(n, np.mean(loss1_list), np.mean(loss2_list), np.mean(loss3_list)))\n",
    "            \n",
    "    def validation_step(self, batch, n):\n",
    "        z = self.encoder(batch)\n",
    "        w1 = self.decoder1(z)\n",
    "        w2 = self.decoder2(z)\n",
    "        w3 = self.decoder2(self.encoder(w1))\n",
    "        \n",
    "        real_recon1 = batch-w1\n",
    "        real_recon2 = batch-w2\n",
    "        fake_recon = batch-w3\n",
    "                \n",
    "        loss1 = 1/n*tf.reduce_mean(tf.square(batch-w1)) + (1-1/n)*tf.reduce_mean(tf.square(batch-w3))\n",
    "        loss2 = 1/n*tf.reduce_mean(tf.square(batch-w2)) + (1-1/n)*tf.reduce_mean(tf.square(batch-w3))\n",
    "        \n",
    "        pg_advantage = tf.reduce_mean(tf.square(fake_recon))-tf.reduce_mean(tf.square(real_recon2))\n",
    "        loss3 = -tf.reduce_mean(tf.math.log(w3+1e-6) * pg_advantage)\n",
    "        \n",
    "        return {'val_loss1': loss1, 'val_loss2': loss2, 'val_loss3': loss3}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses1 = [x['val_loss1'] for x in outputs]\n",
    "        epoch_loss1 = tf.reduce_mean(batch_losses1)\n",
    "        batch_losses2 = [x['val_loss2'] for x in outputs]\n",
    "        epoch_loss2 = tf.reduce_mean(batch_losses2)\n",
    "        batch_losses3 = [x['val_loss3'] for x in outputs]\n",
    "        epoch_loss3 = tf.reduce_mean(batch_losses3)\n",
    "        return {'val_loss1': epoch_loss1.numpy(), 'val_loss2': epoch_loss2.numpy(), 'val_loss3': epoch_loss3.numpy()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss1: {:.4f}, val_loss2: {:.4f}, val_loss2: {:.4f}\".format(epoch, result['val_loss1'], result['val_loss2'], result['val_loss3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Encoder.call of <__main__.Encoder object at 0x00000204D0381B08>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Encoder.call of <__main__.Encoder object at 0x00000204D0381B08>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x00000204CDF717C8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x00000204CDF717C8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x00000204D033C148>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x00000204D033C148>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "usad_agm = UsadModel_AGM(w_size,z_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], val_loss1: 0.2208, val_loss2: 0.2198, val_loss2: -0.0002\n",
      "Epoch [2], val_loss1: 0.2010, val_loss2: 0.1972, val_loss2: -0.0125\n",
      "Epoch [3], val_loss1: 0.1459, val_loss2: 0.1322, val_loss2: -0.0470\n",
      "Epoch [4], val_loss1: 0.0804, val_loss2: 0.0627, val_loss2: -0.0721\n",
      "Epoch [5], val_loss1: 0.0240, val_loss2: 0.0087, val_loss2: -0.1207\n",
      "Epoch [6], val_loss1: 0.0145, val_loss2: 0.0055, val_loss2: -0.0313\n",
      "Epoch [7], val_loss1: 0.0095, val_loss2: 0.0053, val_loss2: -0.0164\n",
      "Epoch [8], val_loss1: 0.0069, val_loss2: 0.0051, val_loss2: -0.0116\n",
      "Epoch [9], val_loss1: 0.0057, val_loss2: 0.0049, val_loss2: -0.0086\n",
      "Epoch [10], val_loss1: 0.0053, val_loss2: 0.0049, val_loss2: -0.0061\n",
      "Epoch [11], val_loss1: 0.0051, val_loss2: 0.0050, val_loss2: -0.0043\n",
      "Epoch [12], val_loss1: 0.0051, val_loss2: 0.0050, val_loss2: -0.0032\n",
      "Epoch [13], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0025\n",
      "Epoch [14], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0022\n",
      "Epoch [15], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0019\n",
      "Epoch [16], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0018\n",
      "Epoch [17], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [18], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [19], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0015\n",
      "Epoch [20], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0015\n",
      "Epoch [21], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0015\n",
      "Epoch [22], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0015\n",
      "Epoch [23], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0015\n",
      "Epoch [24], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0015\n",
      "Epoch [25], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0015\n",
      "Epoch [26], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0015\n",
      "Epoch [27], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0015\n",
      "Epoch [28], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0015\n",
      "Epoch [29], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0015\n",
      "Epoch [30], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0015\n",
      "Epoch [31], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0015\n",
      "Epoch [32], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0015\n",
      "Epoch [33], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0015\n",
      "Epoch [34], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [35], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [36], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [37], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [38], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [39], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [40], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [41], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [42], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [43], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [44], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [45], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [46], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [47], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [48], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [49], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [50], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [51], val_loss1: 0.0051, val_loss2: 0.0051, val_loss2: -0.0016\n",
      "Epoch [52], val_loss1: 0.0050, val_loss2: 0.0051, val_loss2: -0.0017\n",
      "Epoch [53], val_loss1: 0.0050, val_loss2: 0.0051, val_loss2: -0.0017\n",
      "Epoch [54], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [55], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [56], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [57], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [58], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [59], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [60], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [61], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [62], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [63], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [64], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [65], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [66], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [67], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [68], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [69], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [70], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [71], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [72], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [73], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [74], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [75], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [76], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [77], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [78], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [79], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [80], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [81], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [82], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [83], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [84], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [85], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [86], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [87], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [88], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [89], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [90], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [91], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0017\n",
      "Epoch [92], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0018\n",
      "Epoch [93], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0018\n",
      "Epoch [94], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0018\n",
      "Epoch [95], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0018\n",
      "Epoch [96], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0018\n",
      "Epoch [97], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0018\n",
      "Epoch [98], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0018\n",
      "Epoch [99], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0018\n",
      "Epoch [100], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0018\n"
     ]
    }
   ],
   "source": [
    "usad_agm.training(train_loader, test_loader, N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymhjbmvR_DgJ"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model_usad.testing(whole_loader)\n",
    "a = np.concatenate([np.stack(a[:-1]).flatten(), a[-1].flatten()])\n",
    "b = model_usad.testing(train_loader)\n",
    "b = np.concatenate([np.stack(b[:-1]).flatten(), b[-1].flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot([x for x in range(a.shape[0])], a)\n",
    "plt.axhline(y=b.mean() + 5 * b.std(), color='r', linewidth=1)\n",
    "plt.title('Anomaly Detection')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Anomaly Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00023435933144355658"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mean() + 5 * b.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1895"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx = np.max(np.where(a < b.mean() + 5 * b.std())[0]); start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ = a[:start_idx]\n",
    "np.where(a_ > b.mean() + 5 * b.std())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bearing 1_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxFNH5kU9hIE"
   },
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Mfxj4Uxn9kv4"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "x = data1_3.values\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "scaled_data = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "mQ6_U4jn9nlw",
    "outputId": "f1cc1bd6-f1cc-4764-b1cc-2fd989ac4918"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.014028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012601</td>\n",
       "      <td>0.009091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.009587  0.014028\n",
       "1  0.012601  0.009091"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXJi503b-j_d"
   },
   "source": [
    "### Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "vyplttZa-BRN"
   },
   "outputs": [],
   "source": [
    "window_size=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dzGJMp6Y-BN5",
    "outputId": "2949d278-1313-442c-f06b-275a8c6c6578"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2341, 12, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows_normal=scaled_data.values[np.arange(window_size)[None, :] + np.arange(scaled_data.shape[0]-window_size)[:, None]]\n",
    "windows_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k70ZFxGs-_7m"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 100\n",
    "hidden_size = 10\n",
    "\n",
    "w_size=windows_normal.shape[1]*windows_normal.shape[2]\n",
    "z_size=windows_normal.shape[1]*hidden_size\n",
    "\n",
    "windows_normal_train = windows_normal[:400]\n",
    "windows_normal_test = windows_normal[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_normal_train_re = windows_normal_train.reshape(windows_normal_train.shape[0], w_size)\n",
    "windows_normal_test_re = windows_normal_test.reshape(windows_normal_test.shape[0], w_size)\n",
    "windows_normal_re = windows_normal.reshape(windows_normal.shape[0], w_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Dataloader(windows_normal_train_re,windows_normal_train_re,BATCH_SIZE)\n",
    "test_loader = Dataloader(windows_normal_test_re,windows_normal_test_re,BATCH_SIZE)\n",
    "whole_loader = Dataloader(windows_normal_re,windows_normal_re,BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* usad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Encoder.call of <__main__.Encoder object at 0x00000204D170E2C8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Encoder.call of <__main__.Encoder object at 0x00000204D170E2C8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x00000204D1711048>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x00000204D1711048>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x00000204D1719CC8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x00000204D1719CC8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "Epoch [1], val_loss1: 0.2044, val_loss2: 0.2019\n",
      "Epoch [2], val_loss1: 0.1738, val_loss2: 0.1653\n",
      "Epoch [3], val_loss1: 0.1337, val_loss2: 0.1200\n",
      "Epoch [4], val_loss1: 0.0901, val_loss2: 0.0754\n",
      "Epoch [5], val_loss1: 0.0482, val_loss2: 0.0356\n",
      "Epoch [6], val_loss1: 0.0233, val_loss2: 0.0155\n",
      "Epoch [7], val_loss1: 0.0149, val_loss2: 0.0115\n",
      "Epoch [8], val_loss1: 0.0112, val_loss2: 0.0100\n",
      "Epoch [9], val_loss1: 0.0101, val_loss2: 0.0097\n",
      "Epoch [10], val_loss1: 0.0098, val_loss2: 0.0097\n",
      "Epoch [11], val_loss1: 0.0098, val_loss2: 0.0098\n",
      "Epoch [12], val_loss1: 0.0099, val_loss2: 0.0098\n",
      "Epoch [13], val_loss1: 0.0100, val_loss2: 0.0099\n",
      "Epoch [14], val_loss1: 0.0101, val_loss2: 0.0100\n",
      "Epoch [15], val_loss1: 0.0102, val_loss2: 0.0101\n",
      "Epoch [16], val_loss1: 0.0102, val_loss2: 0.0102\n",
      "Epoch [17], val_loss1: 0.0103, val_loss2: 0.0103\n",
      "Epoch [18], val_loss1: 0.0104, val_loss2: 0.0103\n",
      "Epoch [19], val_loss1: 0.0104, val_loss2: 0.0104\n",
      "Epoch [20], val_loss1: 0.0105, val_loss2: 0.0105\n",
      "Epoch [21], val_loss1: 0.0105, val_loss2: 0.0105\n",
      "Epoch [22], val_loss1: 0.0106, val_loss2: 0.0106\n",
      "Epoch [23], val_loss1: 0.0106, val_loss2: 0.0106\n",
      "Epoch [24], val_loss1: 0.0107, val_loss2: 0.0107\n",
      "Epoch [25], val_loss1: 0.0107, val_loss2: 0.0107\n",
      "Epoch [26], val_loss1: 0.0107, val_loss2: 0.0107\n",
      "Epoch [27], val_loss1: 0.0108, val_loss2: 0.0108\n",
      "Epoch [28], val_loss1: 0.0108, val_loss2: 0.0108\n",
      "Epoch [29], val_loss1: 0.0108, val_loss2: 0.0108\n",
      "Epoch [30], val_loss1: 0.0109, val_loss2: 0.0109\n",
      "Epoch [31], val_loss1: 0.0109, val_loss2: 0.0109\n",
      "Epoch [32], val_loss1: 0.0109, val_loss2: 0.0109\n",
      "Epoch [33], val_loss1: 0.0109, val_loss2: 0.0109\n",
      "Epoch [34], val_loss1: 0.0110, val_loss2: 0.0110\n",
      "Epoch [35], val_loss1: 0.0110, val_loss2: 0.0110\n",
      "Epoch [36], val_loss1: 0.0110, val_loss2: 0.0110\n",
      "Epoch [37], val_loss1: 0.0110, val_loss2: 0.0110\n",
      "Epoch [38], val_loss1: 0.0110, val_loss2: 0.0110\n",
      "Epoch [39], val_loss1: 0.0111, val_loss2: 0.0110\n",
      "Epoch [40], val_loss1: 0.0111, val_loss2: 0.0111\n",
      "Epoch [41], val_loss1: 0.0111, val_loss2: 0.0111\n",
      "Epoch [42], val_loss1: 0.0111, val_loss2: 0.0111\n",
      "Epoch [43], val_loss1: 0.0111, val_loss2: 0.0111\n",
      "Epoch [44], val_loss1: 0.0111, val_loss2: 0.0111\n",
      "Epoch [45], val_loss1: 0.0111, val_loss2: 0.0111\n",
      "Epoch [46], val_loss1: 0.0111, val_loss2: 0.0111\n",
      "Epoch [47], val_loss1: 0.0112, val_loss2: 0.0111\n",
      "Epoch [48], val_loss1: 0.0112, val_loss2: 0.0112\n",
      "Epoch [49], val_loss1: 0.0112, val_loss2: 0.0112\n",
      "Epoch [50], val_loss1: 0.0112, val_loss2: 0.0112\n",
      "Epoch [51], val_loss1: 0.0112, val_loss2: 0.0112\n",
      "Epoch [52], val_loss1: 0.0112, val_loss2: 0.0112\n",
      "Epoch [53], val_loss1: 0.0112, val_loss2: 0.0112\n",
      "Epoch [54], val_loss1: 0.0112, val_loss2: 0.0112\n",
      "Epoch [55], val_loss1: 0.0112, val_loss2: 0.0112\n",
      "Epoch [56], val_loss1: 0.0112, val_loss2: 0.0112\n",
      "Epoch [57], val_loss1: 0.0112, val_loss2: 0.0112\n",
      "Epoch [58], val_loss1: 0.0112, val_loss2: 0.0112\n",
      "Epoch [59], val_loss1: 0.0112, val_loss2: 0.0112\n",
      "Epoch [60], val_loss1: 0.0112, val_loss2: 0.0112\n",
      "Epoch [61], val_loss1: 0.0112, val_loss2: 0.0112\n",
      "Epoch [62], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [63], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [64], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [65], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [66], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [67], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [68], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [69], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [70], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [71], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [72], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [73], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [74], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [75], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [76], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [77], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [78], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [79], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [80], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [81], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [82], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [83], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [84], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [85], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [86], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [87], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [88], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [89], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [90], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [91], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [92], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [93], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [94], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [95], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [96], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [97], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [98], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [99], val_loss1: 0.0113, val_loss2: 0.0113\n",
      "Epoch [100], val_loss1: 0.0113, val_loss2: 0.0113\n"
     ]
    }
   ],
   "source": [
    "model_usad = UsadModel(w_size, z_size)\n",
    "model_usad.training(train_loader, test_loader, N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model_usad.testing(whole_loader)\n",
    "a = np.concatenate([np.stack(a[:-1]).flatten(), a[-1].flatten()])\n",
    "b = model_usad.testing(train_loader)\n",
    "b = np.concatenate([np.stack(b[:-1]).flatten(), b[-1].flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd5xddZ3/8dd7anpIhUAqEKRKgAELgoUiVnAVQaWo/MAt2P2toCuy6FrYRX/uigpqVFgVQSxRo4BUlZaETihpSEKAhPRkJlPu/fz+OOfO3JncmdwJOXOnvJ+Px33M6ed7Tib3M9+uiMDMzKyrqkonwMzM+icHCDMzK8kBwszMSnKAMDOzkhwgzMysJAcIMzMryQHCrEySLpX0v5VOx+4mabqkrZKqK50W618cIKzfkHSHpA2S6iudlt1J0kxJkX4Jb5X0oqTfSzqpF9fYbcFJ0jOSTiysR8SzETEqInK74/o2eDhAWL8gaSZwHBDAOyuamOzsERGjgMOBW4BfS/pgZZNk1j0HCOsvzgHuBX4MnFu8Q9KPJV0p6Q+Stki6T9J+RftfK2mBpE3pz9cW7btD0pcl3Z3+9f47SRMk/VTS5vT4mUXHf0vSynTfIknHlUpsmpaPdtn2iKTTdvagEfFCRHwLuBT4uqSq9Py9Jd0oaa2kFZI+lm4/BfgccEb6DA+n28dK+qGk5yU9lz5nezGRpPMlPZG+s8WSjpR0LTAd+F16rX8tyuHUFKVjnqT1kpZKOr/ompdKul7SNel1H5fUsLNntgEqIvzxp+IfYCnwz8BRQCuwZ9G+HwPrgWOAGuCnwHXpvvHABuDsdN/70vUJ6f470mvvB4wFFgNPAyemx18D/KjoXmcBE9J9nwZeAIal+y4F/jddfi9wX9F5hwPrgLoSzzaTJGdU02X7vun2g0j+WFsEXALUpfuWA2/ueu+i838DXAWMBCYD9wMfSfedDjwHHA0I2B+Yke57Bjixu/QBdwLfAYYBc4C1wAlF6dgOvBWoBr4K3Fvp3x9/svk4B2EVJ+l1wAzg+ohYBCwD3t/lsF9FxP0R0UYSIOak298GLImIayOiLSJ+DjwJvKPo3B9FxLKI2AT8EVgWEX9Or3UDcEThwIj434hYl17rCqAeeEWJZP8WmC1pdrp+NvCLiGjpxaOvTn+OJ/kinxQRl0VES0QsB74PnFnqREl7Am8BPhER2yJiDfDNouP/D3B5RCyIxNKI+PvOEiRpGvA64LMRsT0iHgJ+kD5fwV8jYn4kdRbXkgRHG4QcIKw/OBe4OSJeStd/RpdiJpK/5AsagVHp8t5A1y++vwP7FK2/WLTcVGK9cC0kfTotltkkaSNJrmNi1wRHRDNwPXBWWkT0PpIvy94opHE9SYDcW9LGwoekWGnPbs6dAdQCzxcdfxVJTgJgGkmg7a29gfURsaVoW9f32fXfYliheMoGF/+jWkVJGk5SXFMtqfDFUw/sIenwiHh4J5dYTfJlWWw68KddSMtxwGeBE4DHIyIvaQNJEU0pPyEJCn8FGiPinl7e8l3AGuApYA9gRUTM7ubYrsMurwSagYlpTqirlSTFauVcq9hqYLyk0UVBYjpJcZUNMc5BWKWdBuSAg0mKjeaQlMn/haTiemfmAwdIer+kGklnpNf6/S6kZTTQRlLmXiPpEmBMdwenASEPXEEvcg+S9pR0IfBF4OKIyJPUH2yW9FlJwyVVSzpU0tHpaS8CMwsV2hHxPHAzcIWkMZKqJO0n6fXp8T8APiPpKCX2lzSj6Fr7dvNMK4G7ga9KGibplcB5JMV6NsQ4QFilnUtSR/BsJK17XoiIF4BvAx/YWdFFRKwD3k5SobwO+Ffg7UXFVb1xE0kdxdMkxSrbSf4S78k1wGFAOX0UNkraBjxKUsl7ekTMTZ8jR1JvMgdYAbxE8iU/Nj33hvTnOkkPpMvnkFRoLyapmP8lMCW93g3Af5AU120hqdAen573VeDf0qKpz5RI5/tIKq5XA78GvhgRt5TxfDbIKMITBpntKknnABdExOsqnRaz3c05CLNdJGkESdPcqyudFrMsOECY7QJJbyapq3iRpBjHbNBxEZOZmZXkHISZmZU0aPpBTJw4MWbOnFnpZJiZDSiLFi16KSImldo3aALEzJkzWbhwYaWTYWY2oEjqdggWFzGZmVlJDhBmZlaSA4SZmZXkAGFmZiU5QJiZWUkOEGZmVpIDhJmZleQAYWY2gN24aBU/u+/ZTK7tAGFmNoD9+sHn+OWinU1bsmscIMzMBrCm1hzDaqszubYDhJnZALbdAcLMzEpJAkQ2X+UOEGZmA1guH9RWO0CYmVkX+YAqKZNrO0CYmQ1guXyQUXxwgDAzG8gigmrnIMzMrKsBW8Qk6RRJT0laKumiEvs/JWmxpEck3SppRtG+nKSH0s+8LNNpZjZQ5SOoyuibPLMpRyVVA1cCJwGrgAWS5kXE4qLDHgQaIqJR0j8BlwNnpPuaImJOVukzMxsM8hFoAOYgjgGWRsTyiGgBrgNOLT4gIm6PiMZ09V5gaobpMTMbdPLBgKyD2AcoHiBkVbqtO+cBfyxaHyZpoaR7JZ1W6gRJF6THLFy7du3LT7GZ2QCTj6Aqo1ZMmRUxAaWSHCUPlM4CGoDXF22eHhGrJe0L3Cbp0YhY1uliEVcDVwM0NDSUvLaZ2WCWzw/MIqZVwLSi9anA6q4HSToR+DzwzohoLmyPiNXpz+XAHcARGabVzGxAGqitmBYAsyXNklQHnAl0ao0k6QjgKpLgsKZo+zhJ9enyROBYoLhy28zMSIqYMhppI7sipohok3QhcBNQDcyNiMclXQYsjIh5wH8Co4Ab0izSsxHxTuAg4CpJeZIg9rUurZ/MzIxCHUQ2OYgs6yCIiPnA/C7bLilaPrGb8+4GDssybWZmg0E+GJB1EGZmlrF8PrtWTA4QZmYDWFIH4RyEmZl14SImMzPbQUTS/ctFTGZm1kkuXwgQzkGYmVmRND64DsLMzDrLp0VMnlHOzMw6SeODi5jMzKyznCupzcyslHy4ktrMzEqIfPLTAcLMzDrJu4jJzMxKaa+DcDNXMzMr5joIMzMryc1czcyspI6hNrK5vgOEmdkA9YXfPAZAbUZzjjpAmJkNULc+uQaAuhoHCDMzK8E5CDMzK6m22pXUZmZWglsxmZlZaW7FZGZmpWQUHxwgzMwGOhcxmZlZSZ5RzszMSho3oi6T69ZkclUzM8vcHiNq2WN4LYfuMzaT6zsHYWY2QFVJHDd7UnbXz+zKgKRTJD0laamki0rs/5SkxZIekXSrpBlF+86VtCT9nJtlOs3MBqK2XJ7qrEbqI8MAIakauBJ4C3Aw8D5JB3c57EGgISJeCfwSuDw9dzzwReBVwDHAFyWNyyqtZmYDUS4fmfWihmxzEMcASyNieUS0ANcBpxYfEBG3R0RjunovMDVdfjNwS0Ssj4gNwC3AKRmm1cxswGnNB9VV2X2NZxkg9gFWFq2vSrd15zzgj705V9IFkhZKWrh27dqXmVwzs4Ellw9qBmIRE6U790XJA6WzgAbgP3tzbkRcHRENEdEwaVJ2FTVmZv1NRJDLx8CsgyD5q39a0fpUYHXXgySdCHweeGdENPfmXDOzoaotnU1uoNZBLABmS5olqQ44E5hXfICkI4CrSILDmqJdNwEnSxqXVk6fnG4zMzM6phvNsg4is45yEdEm6UKSL/ZqYG5EPC7pMmBhRMwjKVIaBdygpK/4sxHxzohYL+lLJEEG4LKIWJ9VWs3MBppCDiLLOohMe1JHxHxgfpdtlxQtn9jDuXOBudmlzsxs4GrL5QEGbB2EmZllZKDXQZiZWUb6og7CAcLMbABqTYuYBmo/CDMzy0hHDsIBwszMimxvTXIQdTUuYjIzsyK/fyTpOzxl7LDM7uEAYWY2AP3PbUsB2MsBwszMir39lVMAmDpuRGb3KCtASJqRjpmEpOGSRmeWIjMzK8usiSMzvf5OA4Sk80km87kq3TQV+E2WiTIzs541teQYUVed6T3KyUH8C3AssBkgIpYAk7NMlJmZ9ayxnwSI5nRGOAAk1dDNvA5mZtY3GlvaGF6X6XB6ZQWIOyV9Dhgu6STgBuB3mabKzMx61JIL6qqzbWdUztUvAtYCjwIfIRmd9d+yTJSZmfUsnw8yjg89D/ctqRr4SUScBXw/26SYmVm5cpHtdKOwkxxEROSASemMcGZm1k/k80GVsg0Q5dRwPAP8TdI8YFthY0R8I6tEmZlZz/oiB1FOgFidfqoAd5AzM+sHcvmgutI5iIj4d4C093RExNZMU2RmZjuVzwdVlayDAJB0qKQHgceAxyUtknRIpqkyM7Me5SL7HEQ5jaSuBj4VETMiYgbwadyiycysonJ5Kp+DAEZGxO2FlYi4A8h2hCgzM+tRPircDyK1XNIXgGvT9bOAFdklyczMdqYvKqnLiT8fBiYBv0o/E4EPZZkoMzPrWV9UUpfTimkD8LFMU2FmZr3SLyqpJd0iaY+i9XGSbso0VWZm1qNcvsJDbaQmRsTGwkqao/B8EGZmFZSPftAPAshLml5YkTQDzwdhZlZRbf2kkvrzwF8lXSvpWuAu4OJyLi7pFElPSVoq6aIS+4+X9ICkNknv6bIvJ+mh9DOvnPuZmQ0FEUEElR+LKSL+JOlI4NXppk9GxEs7Oy8dKvxK4CRgFbBA0ryIWFx02LPAB4HPlLhEU0TM2dl9zMyGmlw+KcSpWB2EpBmSxgKkAWEbyZf9OWUO/30MsDQilqdTll4HnFp8QEQ8ExGPAPldfQAzs6EmFxUOEMD1pD2mJc0hmWr0WeBw4DtlXHsfYGXR+qp0W7mGSVoo6V5Jp5U6QNIF6TEL165d24tLm5kNXPn0T+pKzgcxPCJWp8tnAXMj4gpJVcBDZVy7VMp7U7k9PSJWS9oXuE3SoxGxrNPFIq4mGSuKhoYGV5yb2ZDQkYPI9j49Xb74C/5NwK0AEVFucdAqYFrR+lSSeSXKUghOEbEcuAM4otxzzcwGs0IdRNY5iJ4CxG2Srpf0LWAccBuApClASxnXXgDMljQrrbM4EyirNVLaGa8+XZ4IHAss7vksM7OhoRAgaipYB/EJkrGXngFeFxGt6fa9SJq+9igi2oALgZuAJ4DrI+JxSZdJeieApKMlrQJOB66S9Hh6+kHAQkkPA7cDX+vS+snMbMhqSyshajIuY+q2DiIigqTlUdftD5Z78YiYD8zvsu2SouUFJEVPXc+7Gzis3PuYmQ0l/SEHYWZm/VBbLg0QGecgHCDMzAaYtv6Sg5D09rRpq5mZ9QNtuUIdROWLmM4Elki6XNJBmabGzMx2qt/kICLiLJI+CMuAH0m6J+3BPDrTlJmZWUmthRxEVT+og4iIzcCNJK2apgDvAh6Q9NEM02ZmZiU0tyUBYlhtdab3KacO4h2Sfk3SUa4WOCYi3kIyJlOpUVjNzCxDn7guGe2ovrZC/SCKnA58MyLuKt4YEY2SPpxNsszMrDvPbWwCYFhNtjmIcuaDOKeHfbfu3uSYmVm5RtZXKEBI2kLn0VeVrouko/WYTFNmZmY9mjZ+RKbX72moDbdSMjPrh0YPq+HdR06ltlJjMXUlaTIwrLAeEc9mkiIzM+tRay5PfU32/ZfLacX0TklLgBXAnSSju/4x43SZmVk3WtrymeceoLx+EF8CXg08HRGzgBOAv2WaKjMzKymXD/IBdf0hBwG0RsQ6oEpSVUTcDszJOF1mZlZCS9pJri9yEOXUQWyUNAq4C/ippDVAW7bJMjOzUlrSYTb6Sw7iVKAJ+CTwJ5Ixmd6RZaLMzKy0Qg6iLuORXKG8jnLbACSNAX6XeYrMzKxbfZmD2GmAkPQR4DKSXESejg5z+2abNDMz66q1n9VBfAY4JCJeyjoxZmbWve2tOT768weB/lMHsQxozDohZmbWs2/ftpRHn9sEZD8XBJSXg7gYuFvSfUBzYWNEfCyzVJmZ2Q6+ffvS9uWMJ5MDygsQV5HMBfEoSR2EmZlVWJX6QSsmoC0iPpV5SszMrGx9EB/KqoO4PZ2Deoqk8YVP5ikzM7Nu9UWAKCcH8f7058VF29zM1cysj+0xopaNja0AiH5QxJQO0GdmZhU2bdwINjYmrZj6RQ5CUi3wT8Dx6aY7gKsiojXDdJmZWRetuY52QoftMzbz+5VTB/Fd4CjgO+nnqHTbTkk6RdJTkpZKuqjE/uMlPSCpTdJ7uuw7V9KS9HNuOfczMxvMcvngbYdN4ZmvvY0Jo+ozv185dRBHR8ThReu3SXp4ZydJqgauBE4CVgELJM2LiMVFhz0LfJCkt3bxueOBLwINJPUdi9JzN5SRXjOzQaktH1T3RQeIVDk5iJyk/QorkvYFcmWcdwywNCKWR0QLcB3JyLDtIuKZiHiEHftXvBm4JSLWp0HhFuCUMu5pZjZoteby1PTBKK4F5eQg/i9JU9flJAP1zQA+VMZ5+wAri9ZXAa8qM12lzt2nzHPNzAalXD6o6cMcRDmtmG6VNBt4BUmAeDIimndyGumxO1yuzHSVda6kC4ALAKZPn17mpc3MBqbWXFDTB6O4FpR7p6OAQ4HDgTMknVPGOauAaUXrU4HVZd6vrHMj4uqIaIiIhkmTJpV5aTOzgSmXz/evHISka4H9gIfoqHsI4JqdnLoAmC1pFvAccCYdne525ibgK5LGpesn07mjnpnZkNOW69tK6nLqIBqAgyOi3OIhACKiTdKFJF/21cDciHhc0mXAwoiYJ+lo4NfAOOAdkv49Ig6JiPWSvkQSZAAui4j1vbm/mdlg05aPPpkoqKCcAPEYsBfwfG8vHhHzgfldtl1StLyApPio1Llzgbm9vaeZ2WDVls/3uxzERGCxpPvpPB/EOzNLlZmZ7aAtH9T2swBxadaJMDOznuXyQQRU98FMcgXlNHO9s3hd0rEklc13lj7DzMx2t7Z80p+4v3WUQ9IckqDwXmAFcGOWiTIzs87ackk7oX7RzFXSASRNU98HrAN+ASgi3thHaTMzs1RhJNe6mv5RxPQk8BfgHRGxFEDSJ/skVWZm1klzWxIg6muq++yePYWidwMvkIzD9H1JJ1B6CAwzM8tYc2shQPSDoTYi4tcRcQZwIMkkQZ8E9pT0XUkn91H6zMwM2NKczNFWX9sPAkRBRGyLiJ9GxNtJOrU9BOww+Y+ZmWVn5fomAPYcM6zP7tmrUJTOz3BVRLwpqwSZmdmOtjW3ATB5dPYzyRX0XV7FzMx2WWNrMlbq8Lr+UUltZmb9xPaWJEAMq3WAMDOzIi2FfhD9cMIgMzPrIxHBor+vp3iWhVYHCDOzoe3e5eu4YdEq3v3de7h+4cr27S1tyWxyVf1hqA0zM+tbL2zazplX39u+/tkbH+WMo6cDSQ6iLycLAucgzMz6ja1pZ7hiqzY0AtCaiz4dhwkcIMzM+o3N29t22HbpvMVAMhaTcxBmZkPU5qYdcxD3r1gHJEVMdX04FwQ4QJiZ9RulchCj6pOq4tZcnloXMZmZDU0P/H3DDtumTxgBJK2Y+rKJKzhAmJn1Gz+++5lO69PHj6DQFcKtmMzMrN308SPae1C35MJFTGZmlhhWW90+UVBLW4565yDMzIaev6/b1r48cVQypHd9TRXNbckgfa25oLbGrZjMzIacxas3ty/f+qnXc+/FJ6QBIslBVKIOwkNtmJn1A1KSO3jfMdMZO6KWsdRSX9sRINyKycxsiGpqTfpAnH/crPZtw2tr2NTUSmsuT4v7QZiZDU1NLUlOYURdR8HOvpNG0tKW56WtzWlP6kEUICSdIukpSUslXVRif72kX6T775M0M90+U1KTpIfSz/eyTKeZWaU1tiQ5iOIpRSeMrANg9camihQxZVYHIakauBI4CVgFLJA0LyIWFx12HrAhIvaXdCbwdeCMdN+yiJiTVfrMzPqTpnRK0RFFASKtluC8nyykShpUrZiOAZZGxPKIaAGuA07tcsypwE/S5V8CJ6hQU2NmNoQ0tuaorVanlkp7jR0OwMbGVloH2Wiu+wAri9ZXpdtKHhMRbcAmYEK6b5akByXdKem4UjeQdIGkhZIWrl27dvem3sysDzW15BheW91p25xpewBw0sF70tiaY2Rd3zY8zTJAlMoJRJnHPA9Mj4gjgE8BP5M0ZocDI66OiIaIaJg0adLLTrCZWaU0trR1qn8oaJgxjmVrt5LLB3vvMbxP05RlgFgFTCtanwqs7u4YSTXAWGB9RDRHxDqAiFgELAMOyDCtZmYV1dSa79SCqWDiqHpe2LQdgJpBNB/EAmC2pFmS6oAzgXldjpkHnJsuvwe4LSJC0qS0khtJ+wKzgeUZptXMrKKaWtp2KGICmDi6jsa0AnvQtGKKiDZJFwI3AdXA3Ih4XNJlwMKImAf8ELhW0lJgPUkQATgeuExSG5AD/jEi1meVVjOzSmtsyXVqwVQwbkRd+3Jf5yAyrfGIiPnA/C7bLila3g6cXuK8G4Ebs0ybmVml5fLBf/zhCT507EzWb2th6rgd6xiGFeUqaqoGSQ7CzMx69sTzm5n7txU8vGoja7Y00zBz3A7HFBc71Q6iOggzsyFje2uO1nRyn3IVBuJrasmxtbmNkfU7/s1e3LJpMPWDMDMbEprbchz4hT/xge/f16vzNmxrAWBkfTUtbfmS/RyKcxDF9RF9wQHCzKwMmxpbaWkrnUP446MvAHD/M71rS/Pfty0BoC4dpbVUDqK6qqNYafwoBwgzsz63vTXX4/7DL7uZj1y7sOS+lesbd+mej6zaBMDo+loARpZoxZSPjv7F40bU7tJ9dpUDhJkNeSvXN3LgF/7EDQtX9njc7U+VHtLnyRe2tC9HdB0wAp7b2MQlv32s2xzItnQk1xElchBvOXQKH33T/lxx+uElO9Jlya2YzGzIW7Z2KwC/euA5Tm+Y1uOxjS1tO3xRb2hsaV9+aWsLk0bXd9p/7NduA2D2nqM5+9UzADoFi83bkwBRKgdRV1PFp09+RbmPsls5B2FmQ966rckX/KK/byi5vzhXcEeJXMTW5rb25V8uWtXtfdZs3t6+vKmptX15S7rc1zmEnXGAMLMhb+3WZgBacnly+R2LiIq3FecWIAkOhboEgK//6cn21kldFfdi6BQg0gAzqkQRUyU5QJjZkLcuDRAAS9Zs2WF/rigHsX5r5y//wkB6xe5a0jmXcdCUZDDq7UXFSp0CxPY0B1G/YxFTJTlAmNmQcsE1C/nq/Cc6bWsqasH0fJcv/It/9Qg/v+/Z9vV1XXIHhS/6hhkdvaA/ft1DnY7Z2tya/uwoinqpKChtb00CR1/P97Az/Ss1ZmYZ2trcxs2LXwTgs6ccSFXax6CppeMv+8bmzs1df35/55ZNK17aBsCz6xoZN7KWzelf/59720Fcd/+zXL8wqYNoy+WpSXs+b0krobcVBYg1W5rpaszw/vWV7ByEmQ1Kz29q4ku/X8yjRfUDJ1xxR/tyc1Fxz/a2XHtntUKTU6Dk0BlLXkyKoI7/z9s5/Xv3sDnNQYwZVsvl7zmcNx+yJ5C0iIKkgrsQILZu77h2rsu1R9RVu5LazKwvXHHz0/zwryt4x7f/2r5t/MiO5qfNbbn21knNrTkmjkx6KTcW/ZVfXE8ASSXymi3N7fUOT76whbVpTmDs8KQT2yF7jwXgX298hN89vJrGllx7JfeWogDRtS58/Mi+7SVdDgcIMxsw7lu+jq+k9QcR0d5/AZK/9otzC6Wamx4xfY/25TufXsucy25hxUvbaGrNMWFUEjy2tXQUMd30+Audzp88up5cBLc88WL7tqdf3MLw2ur2Xs5nHN3Rj+KjP3+Qb926pH29UBwFHT2kTz9qKkD7/fsTBwgzGzDOuPperr5rOVub27jj6bWccMWd/O7hZCbjQm5h5kV/6HbYjOLOaR+/7iE2NbVy19Nr2d6aZ8zwGuqqq9jc1Mp/37qEs394H1fc/DQA7ztmOgBvPHAyEUmgKrh+4SqaWnPt9Q17jhnW6Z5X35VMhjmirro9B7F0zdb2znGFbX08kndZ+leBl5lZGRasWM/jq5PcwgPPbuAdh+/NXU93NC0tHvoCksrh1RubSuYqmlpzbN3exviRI9h7j2Gs2tDEHx59HoDR9TW8+8ipfPUfDuOr/3AY/5PmBn7/yPO9TvPsPUezYu1WLvntY1xzz9/btxcG4Htw5cZeXzNrzkGYWb/x/KYmfvPgczs97kM/XsD8dATVW59YA3TuhfyNW5K//AtDVxzyxZs46Zt3lbzWms3NrHhpG/tOHMnUcSPagwMkHdheNWt8+3p1N3/m/9Mb9uu0fvl7XrnDMftNGsm2llyn4ADwsTfNBuDY/SaWvHYlOUCYWb/xoR8t4BO/eKhTH4GCh7r8hV1oYfTs+kYigrZ8nvq0JVIhN1Fcn9CdRc9uoCWX5xV7jS455eeconqLmqKhtz9z8gHty1PGdi5Wem/DtPbWTAXTxo0o2Ut70uh6fvyho/ne2UftNK19zQHCzPqF5rZce9HQrx5Y1Wn8o6vvWsZpV/6t0/FL1nRUUJ8z937ueGotE7q0BDr3NTN2uM8bXjGpffngKWN4OA08+08exbTxI3Y4ftbEke3LVeoIEG88cHL78vGzJ9HVN947h2G1HV+xE0eXroSuErzhFZP73TAb4ABhZv3EbWlREcBX5j/JrIvnc8+yddy97CW+Mv/J9n3FPZY/+NqZAPxlyUsArC7qBX3MrPH88xv356qzj+LmTx7P3y56EwBHTOs4f/KYji/t8SPrOgWDy9/9Su74zBs6TfO5ragT3eTRHbmGmUXnFYysr+HTJ3WMwtpdHbTUD2unU/0vZJnZoLdyfSO/XLSKj75p//bWP9+5Y9kOx73v+/fusO1TJx/A+9OpPU+dszc/vvuZ9n0/O/9V7DVmGJPHDGv/i/zNh+zVvv/+z53A+JF1fPPPSR3FhKJ+EaOH1bbP6DZuRC3vPXrHYb+Xv9SRayn0e9h/8qhun/P84/dlRH01qzc2MWdaR1HV+cfN4vt/WdHtef2FA4SZ9bnTv3cPL2zezqH7jGVUfQ2jh9Xw6HObdnrel047lCljO+oJXjm140v3e2cdxWt3UtE7uagJ6tjhtZ06wo2qr+H42RP50QeP5vgDdiniYkoAAAiQSURBVCwyApg5oSOnUFdTxTUfPobD9hnb4z0/8Kodi7nOfe1MBwgzs1JeSOdFOP+aHafw/NMnjuPZdY3sO2kkP79/JT/8a/JFessnj2fWxJG0FVX0VleJmRNG8OLmZk45dK8drtWd2z/zBkbWVbNqYxN/Tju9FeZ+Lq5b6Oqjb9qfa+55htfsNwGg20DSnbrqKkbWVzN13AgOmjKGxqJhPfojBwgz61OP9ZBTeNsrp3DgXmM4cK9keOzPvfUg9hxTzxkN0xmb9lSu6TIi9i2fej0lZvnsUaGuYfKYYXzgVdNpLKO1U3LvKh685OTe3azIw188mUKVwx8/ftwuX6evOECYWZ+6Ku1Z/OFjZzH3b52LWeqrO7ebqa4SFxzfuY8BwA3/+Jr2OoDa6pfX1uY/3nXYyzq/N4aXmFK0P3MrJjPrU63pcBefe+uBQNLUtND/IFdmVuDomeM5YM/R2STQ2jkHYWa7TS4f7WX5XeXzweLnN/Onx1/gxIMmU1NdxdNffgvVVeIvS9bywR8t6HYMJauMTAOEpFOAbwHVwA8i4mtd9tcD1wBHAeuAMyLimXTfxcB5QA74WETclGVazWzXbdjWwhFfuqV9feG/nciIumqWvLiVupoqZk0cScOX/9w+o9rr08rdwhwMr953Ame/egbnvW5W3yfeupVZgJBUDVwJnASsAhZImhcRi4sOOw/YEBH7SzoT+DpwhqSDgTOBQ4C9gT9LOiAi/OeFWT+zdkvzDq2RGr785x7PKYyOWjCstpovnXbobk+bvTxZ5iCOAZZGxHIASdcBpwLFAeJU4NJ0+ZfAt5V0KzwVuC4imoEVkpam17tndydyY2ML7/rO3bv7smWJ3ja92F33rchd6XVLk912X6Ji994VuyutPXXQ7XFft31+k/MikqKkfCSfFzd3TJjz/86cw3/d9BSPr968wzkAj1x6MmOG1fbqOaxysgwQ+wDFk7muAl7V3TER0SZpEzAh3X5vl3P36XoDSRcAF0BSRtXjb3039gBu7/VZZlbSpfDGnvZ/vY/SYbtFlgGi1Ld117+NujumnHOJiKuBqwEaGhqChTt2ujEzsx708Id1ls1cVwHFg5lMBVZ3d4ykGmAssL7Mc83MLENZBogFwGxJsyTVkVQ6z+tyzDzg3HT5PcBtkRTMzwPOlFQvaRYwG7g/w7SamVkXmRUxpXUKFwI3kTRznRsRj0u6DFgYEfOAHwLXppXQ60mCCOlx15NUaLcB/+IWTGZmfUuVakmzuzU0NMRC10GYmfWKpEUR0VBqn4faMDOzkhwgzMysJAcIMzMryQHCzMxKGjSV1JLWAn9/GZeYCLy0m5IzUPkd+B2A3wEMrXcwIyJKTo03aALEyyVpYXc1+UOF34HfAfgdgN9BgYuYzMysJAcIMzMryQGiw9WVTkA/4HfgdwB+B+B3ALgOwszMuuEchJmZleQAYWZmJQ35ACHpFElPSVoq6aJKpydLkp6R9KikhyQtTLeNl3SLpCXpz3Hpdkn67/S9PCLpyMqmftdImitpjaTHirb1+pklnZsev0TSuaXu1V918w4ulfRc+rvwkKS3Fu27OH0HT0l6c9H2Aft/RdI0SbdLekLS45I+nm4fUr8LvRYRQ/ZDMgz5MmBfoA54GDi40unK8HmfASZ22XY5cFG6fBHw9XT5rcAfSWb3ezVwX6XTv4vPfDxwJPDYrj4zMB5Ynv4cly6Pq/Szvcx3cCnwmRLHHpz+P6gHZqX/P6oH+v8VYApwZLo8Gng6fdYh9bvQ289Qz0EcAyyNiOUR0QJcB5xa4TT1tVOBn6TLPwFOK9p+TSTuBfaQNKUSCXw5IuIukrlGivX2md8M3BIR6yNiA3ALcEr2qd89unkH3TkVuC4imiNiBbCU5P/JgP6/EhHPR8QD6fIW4AmSee6H1O9Cbw31ALEPsLJofVW6bbAK4GZJiyRdkG7bMyKeh+Q/ETA53T6Y301vn3mwvosL0+KTuYWiFYbAO5A0EzgCuA//LvRoqAeIUrN1D+Z2v8dGxJHAW4B/kXR8D8cOtXcD3T/zYHwX3wX2A+YAzwNXpNsH9TuQNAq4EfhERGzu6dAS2wbNeyjXUA8Qq4BpRetTgdUVSkvmImJ1+nMN8GuSYoMXC0VH6c816eGD+d309pkH3buIiBcjIhcReeD7JL8LMIjfgaRakuDw04j4Vbp5yP8u9GSoB4gFwGxJsyTVkcyJPa/CacqEpJGSRheWgZOBx0iet9AS41zgt+nyPOCctDXHq4FNhaz4INDbZ74JOFnSuLQo5uR024DVpT7pXSS/C5C8gzMl1UuaBcwG7meA/1+RJOCHwBMR8Y2iXUP+d6FHla4lr/SHpLXC0yQtND5f6fRk+Jz7krQ8eRh4vPCswATgVmBJ+nN8ul3Alel7eRRoqPQz7OJz/5ykCKWV5K+/83blmYEPk1TYLgU+VOnn2g3v4Nr0GR8h+TKcUnT859N38BTwlqLtA/b/CvA6kqKgR4CH0s9bh9rvQm8/HmrDzMxKGupFTGZm1g0HCDMzK8kBwszMSnKAMDOzkhwgzMyspJpKJ8BsoJFUaBoJsBeQA9am640R8dqKJMxsN3MzV7OXQdKlwNaI+K9Kp8Vsd3MRk9luJGlr+vMNku6UdL2kpyV9TdIHJN2vZE6O/dLjJkm6UdKC9HNsZZ/ArIMDhFl2Dgc+DhwGnA0cEBHHAD8APpoe8y3gmxFxNPDudJ9Zv+A6CLPsLIh0/CpJy4Cb0+2PAm9Ml08EDk6GCgJgjKTRkcxZYFZRDhBm2WkuWs4Xrefp+L9XBbwmIpr6MmFm5XARk1ll3QxcWFiRNKeCaTHrxAHCrLI+BjSkM7stBv6x0gkyK3AzVzMzK8k5CDMzK8kBwszMSnKAMDOzkhwgzMysJAcIMzMryQHCzMxKcoAwM7OS/j+YweuYHgW2qgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot([x for x in range(a.shape[0])], a)\n",
    "plt.axhline(y=b.mean() + 5 * b.std(), color='r', linewidth=1)\n",
    "plt.title('Anomaly Detection')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Anomaly Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00010550405386311468"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mean() + 5 * b.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx = np.max(np.where(a < b.mean() + 5 * b.std())[0]); start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ = a[:start_idx]\n",
    "np.where(a_ > b.mean() + 5 * b.std())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* usad agm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Encoder.call of <__main__.Encoder object at 0x00000204D06BC8C8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Encoder.call of <__main__.Encoder object at 0x00000204D06BC8C8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x00000204D197EF08>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x00000204D197EF08>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x00000204D19AE5C8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x00000204D19AE5C8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "usad_agm = UsadModel_AGM(w_size,z_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], val_loss1: 0.2024, val_loss2: 0.2027, val_loss2: 0.0004\n",
      "Epoch [2], val_loss1: 0.1795, val_loss2: 0.1768, val_loss2: -0.0133\n",
      "Epoch [3], val_loss1: 0.1217, val_loss2: 0.1117, val_loss2: -0.0625\n",
      "Epoch [4], val_loss1: 0.0557, val_loss2: 0.0401, val_loss2: -0.1719\n",
      "Epoch [5], val_loss1: 0.0269, val_loss2: 0.0140, val_loss2: -0.1356\n",
      "Epoch [6], val_loss1: 0.0190, val_loss2: 0.0124, val_loss2: -0.0616\n",
      "Epoch [7], val_loss1: 0.0141, val_loss2: 0.0115, val_loss2: -0.0408\n",
      "Epoch [8], val_loss1: 0.0115, val_loss2: 0.0105, val_loss2: -0.0331\n",
      "Epoch [9], val_loss1: 0.0107, val_loss2: 0.0103, val_loss2: -0.0285\n",
      "Epoch [10], val_loss1: 0.0104, val_loss2: 0.0101, val_loss2: -0.0266\n",
      "Epoch [11], val_loss1: 0.0102, val_loss2: 0.0100, val_loss2: -0.0268\n",
      "Epoch [12], val_loss1: 0.0100, val_loss2: 0.0098, val_loss2: -0.0295\n",
      "Epoch [13], val_loss1: 0.0097, val_loss2: 0.0095, val_loss2: -0.0379\n",
      "Epoch [14], val_loss1: 0.0094, val_loss2: 0.0089, val_loss2: -0.0589\n",
      "Epoch [15], val_loss1: 0.0088, val_loss2: 0.0079, val_loss2: -0.1106\n",
      "Epoch [16], val_loss1: 0.0095, val_loss2: 0.0081, val_loss2: -0.2311\n",
      "Epoch [17], val_loss1: 0.0093, val_loss2: 0.0084, val_loss2: -0.2377\n",
      "Epoch [18], val_loss1: 0.0089, val_loss2: 0.0084, val_loss2: -0.2327\n",
      "Epoch [19], val_loss1: 0.0095, val_loss2: 0.0093, val_loss2: -0.2689\n",
      "Epoch [20], val_loss1: 0.0105, val_loss2: 0.0106, val_loss2: -0.3218\n",
      "Epoch [21], val_loss1: 0.0112, val_loss2: 0.0117, val_loss2: -0.3785\n",
      "Epoch [22], val_loss1: 0.0120, val_loss2: 0.0126, val_loss2: -0.4505\n",
      "Epoch [23], val_loss1: 0.0110, val_loss2: 0.0117, val_loss2: -0.4319\n",
      "Epoch [24], val_loss1: 0.0092, val_loss2: 0.0097, val_loss2: -0.3503\n",
      "Epoch [25], val_loss1: 0.0080, val_loss2: 0.0084, val_loss2: -0.2903\n",
      "Epoch [26], val_loss1: 0.0070, val_loss2: 0.0074, val_loss2: -0.2215\n",
      "Epoch [27], val_loss1: 0.0066, val_loss2: 0.0069, val_loss2: -0.1844\n",
      "Epoch [28], val_loss1: 0.0065, val_loss2: 0.0066, val_loss2: -0.1361\n",
      "Epoch [29], val_loss1: 0.0065, val_loss2: 0.0067, val_loss2: -0.1083\n",
      "Epoch [30], val_loss1: 0.0067, val_loss2: 0.0068, val_loss2: -0.0879\n",
      "Epoch [31], val_loss1: 0.0069, val_loss2: 0.0070, val_loss2: -0.0744\n",
      "Epoch [32], val_loss1: 0.0071, val_loss2: 0.0071, val_loss2: -0.0639\n",
      "Epoch [33], val_loss1: 0.0073, val_loss2: 0.0073, val_loss2: -0.0560\n",
      "Epoch [34], val_loss1: 0.0074, val_loss2: 0.0075, val_loss2: -0.0499\n",
      "Epoch [35], val_loss1: 0.0076, val_loss2: 0.0076, val_loss2: -0.0454\n",
      "Epoch [36], val_loss1: 0.0077, val_loss2: 0.0077, val_loss2: -0.0418\n",
      "Epoch [37], val_loss1: 0.0079, val_loss2: 0.0079, val_loss2: -0.0382\n",
      "Epoch [38], val_loss1: 0.0080, val_loss2: 0.0080, val_loss2: -0.0355\n",
      "Epoch [39], val_loss1: 0.0081, val_loss2: 0.0081, val_loss2: -0.0331\n",
      "Epoch [40], val_loss1: 0.0082, val_loss2: 0.0082, val_loss2: -0.0313\n",
      "Epoch [41], val_loss1: 0.0083, val_loss2: 0.0083, val_loss2: -0.0298\n",
      "Epoch [42], val_loss1: 0.0084, val_loss2: 0.0084, val_loss2: -0.0283\n",
      "Epoch [43], val_loss1: 0.0084, val_loss2: 0.0084, val_loss2: -0.0269\n",
      "Epoch [44], val_loss1: 0.0085, val_loss2: 0.0085, val_loss2: -0.0260\n",
      "Epoch [45], val_loss1: 0.0086, val_loss2: 0.0086, val_loss2: -0.0252\n",
      "Epoch [46], val_loss1: 0.0086, val_loss2: 0.0086, val_loss2: -0.0243\n",
      "Epoch [47], val_loss1: 0.0087, val_loss2: 0.0087, val_loss2: -0.0234\n",
      "Epoch [48], val_loss1: 0.0087, val_loss2: 0.0087, val_loss2: -0.0227\n",
      "Epoch [49], val_loss1: 0.0088, val_loss2: 0.0088, val_loss2: -0.0221\n",
      "Epoch [50], val_loss1: 0.0088, val_loss2: 0.0088, val_loss2: -0.0216\n",
      "Epoch [51], val_loss1: 0.0088, val_loss2: 0.0088, val_loss2: -0.0210\n",
      "Epoch [52], val_loss1: 0.0089, val_loss2: 0.0089, val_loss2: -0.0202\n",
      "Epoch [53], val_loss1: 0.0089, val_loss2: 0.0089, val_loss2: -0.0200\n",
      "Epoch [54], val_loss1: 0.0090, val_loss2: 0.0090, val_loss2: -0.0195\n",
      "Epoch [55], val_loss1: 0.0090, val_loss2: 0.0090, val_loss2: -0.0190\n",
      "Epoch [56], val_loss1: 0.0090, val_loss2: 0.0090, val_loss2: -0.0186\n",
      "Epoch [57], val_loss1: 0.0091, val_loss2: 0.0091, val_loss2: -0.0183\n",
      "Epoch [58], val_loss1: 0.0091, val_loss2: 0.0091, val_loss2: -0.0179\n",
      "Epoch [59], val_loss1: 0.0091, val_loss2: 0.0091, val_loss2: -0.0176\n",
      "Epoch [60], val_loss1: 0.0092, val_loss2: 0.0092, val_loss2: -0.0173\n",
      "Epoch [61], val_loss1: 0.0092, val_loss2: 0.0092, val_loss2: -0.0170\n",
      "Epoch [62], val_loss1: 0.0092, val_loss2: 0.0092, val_loss2: -0.0168\n",
      "Epoch [63], val_loss1: 0.0092, val_loss2: 0.0092, val_loss2: -0.0165\n",
      "Epoch [64], val_loss1: 0.0093, val_loss2: 0.0093, val_loss2: -0.0162\n",
      "Epoch [65], val_loss1: 0.0093, val_loss2: 0.0093, val_loss2: -0.0161\n",
      "Epoch [66], val_loss1: 0.0093, val_loss2: 0.0093, val_loss2: -0.0157\n",
      "Epoch [67], val_loss1: 0.0093, val_loss2: 0.0093, val_loss2: -0.0155\n",
      "Epoch [68], val_loss1: 0.0094, val_loss2: 0.0094, val_loss2: -0.0153\n",
      "Epoch [69], val_loss1: 0.0094, val_loss2: 0.0094, val_loss2: -0.0151\n",
      "Epoch [70], val_loss1: 0.0094, val_loss2: 0.0094, val_loss2: -0.0151\n",
      "Epoch [71], val_loss1: 0.0094, val_loss2: 0.0094, val_loss2: -0.0149\n",
      "Epoch [72], val_loss1: 0.0094, val_loss2: 0.0094, val_loss2: -0.0146\n",
      "Epoch [73], val_loss1: 0.0095, val_loss2: 0.0095, val_loss2: -0.0144\n",
      "Epoch [74], val_loss1: 0.0095, val_loss2: 0.0095, val_loss2: -0.0143\n",
      "Epoch [75], val_loss1: 0.0095, val_loss2: 0.0095, val_loss2: -0.0142\n",
      "Epoch [76], val_loss1: 0.0095, val_loss2: 0.0095, val_loss2: -0.0140\n",
      "Epoch [77], val_loss1: 0.0095, val_loss2: 0.0095, val_loss2: -0.0139\n",
      "Epoch [78], val_loss1: 0.0095, val_loss2: 0.0095, val_loss2: -0.0136\n",
      "Epoch [79], val_loss1: 0.0095, val_loss2: 0.0095, val_loss2: -0.0135\n",
      "Epoch [80], val_loss1: 0.0096, val_loss2: 0.0096, val_loss2: -0.0135\n",
      "Epoch [81], val_loss1: 0.0096, val_loss2: 0.0096, val_loss2: -0.0133\n",
      "Epoch [82], val_loss1: 0.0096, val_loss2: 0.0096, val_loss2: -0.0133\n",
      "Epoch [83], val_loss1: 0.0096, val_loss2: 0.0096, val_loss2: -0.0131\n",
      "Epoch [84], val_loss1: 0.0096, val_loss2: 0.0096, val_loss2: -0.0130\n",
      "Epoch [85], val_loss1: 0.0096, val_loss2: 0.0096, val_loss2: -0.0127\n",
      "Epoch [86], val_loss1: 0.0097, val_loss2: 0.0097, val_loss2: -0.0127\n",
      "Epoch [87], val_loss1: 0.0097, val_loss2: 0.0097, val_loss2: -0.0125\n",
      "Epoch [88], val_loss1: 0.0097, val_loss2: 0.0097, val_loss2: -0.0124\n",
      "Epoch [89], val_loss1: 0.0097, val_loss2: 0.0097, val_loss2: -0.0123\n",
      "Epoch [90], val_loss1: 0.0097, val_loss2: 0.0097, val_loss2: -0.0122\n",
      "Epoch [91], val_loss1: 0.0097, val_loss2: 0.0097, val_loss2: -0.0121\n",
      "Epoch [92], val_loss1: 0.0097, val_loss2: 0.0097, val_loss2: -0.0120\n",
      "Epoch [93], val_loss1: 0.0097, val_loss2: 0.0097, val_loss2: -0.0120\n",
      "Epoch [94], val_loss1: 0.0098, val_loss2: 0.0098, val_loss2: -0.0118\n",
      "Epoch [95], val_loss1: 0.0098, val_loss2: 0.0098, val_loss2: -0.0118\n",
      "Epoch [96], val_loss1: 0.0098, val_loss2: 0.0098, val_loss2: -0.0116\n",
      "Epoch [97], val_loss1: 0.0098, val_loss2: 0.0098, val_loss2: -0.0116\n",
      "Epoch [98], val_loss1: 0.0098, val_loss2: 0.0098, val_loss2: -0.0115\n",
      "Epoch [99], val_loss1: 0.0098, val_loss2: 0.0098, val_loss2: -0.0114\n",
      "Epoch [100], val_loss1: 0.0098, val_loss2: 0.0098, val_loss2: -0.0112\n"
     ]
    }
   ],
   "source": [
    "usad_agm.training(train_loader, test_loader, N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model_usad.testing(whole_loader)\n",
    "a = np.concatenate([np.stack(a[:-1]).flatten(), a[-1].flatten()])\n",
    "b = model_usad.testing(train_loader)\n",
    "b = np.concatenate([np.stack(b[:-1]).flatten(), b[-1].flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd5xddZ3/8dd7anpIhUAqEKRKgAELgoUiVnAVQaWo/MAt2P2toCuy6FrYRX/uigpqVFgVQSxRo4BUlZaETihpSEKAhPRkJlPu/fz+OOfO3JncmdwJOXOnvJ+Px33M6ed7Tib3M9+uiMDMzKyrqkonwMzM+icHCDMzK8kBwszMSnKAMDOzkhwgzMysJAcIMzMryQHCrEySLpX0v5VOx+4mabqkrZKqK50W618cIKzfkHSHpA2S6iudlt1J0kxJkX4Jb5X0oqTfSzqpF9fYbcFJ0jOSTiysR8SzETEqInK74/o2eDhAWL8gaSZwHBDAOyuamOzsERGjgMOBW4BfS/pgZZNk1j0HCOsvzgHuBX4MnFu8Q9KPJV0p6Q+Stki6T9J+RftfK2mBpE3pz9cW7btD0pcl3Z3+9f47SRMk/VTS5vT4mUXHf0vSynTfIknHlUpsmpaPdtn2iKTTdvagEfFCRHwLuBT4uqSq9Py9Jd0oaa2kFZI+lm4/BfgccEb6DA+n28dK+qGk5yU9lz5nezGRpPMlPZG+s8WSjpR0LTAd+F16rX8tyuHUFKVjnqT1kpZKOr/ompdKul7SNel1H5fUsLNntgEqIvzxp+IfYCnwz8BRQCuwZ9G+HwPrgWOAGuCnwHXpvvHABuDsdN/70vUJ6f470mvvB4wFFgNPAyemx18D/KjoXmcBE9J9nwZeAIal+y4F/jddfi9wX9F5hwPrgLoSzzaTJGdU02X7vun2g0j+WFsEXALUpfuWA2/ueu+i838DXAWMBCYD9wMfSfedDjwHHA0I2B+Yke57Bjixu/QBdwLfAYYBc4C1wAlF6dgOvBWoBr4K3Fvp3x9/svk4B2EVJ+l1wAzg+ohYBCwD3t/lsF9FxP0R0UYSIOak298GLImIayOiLSJ+DjwJvKPo3B9FxLKI2AT8EVgWEX9Or3UDcEThwIj434hYl17rCqAeeEWJZP8WmC1pdrp+NvCLiGjpxaOvTn+OJ/kinxQRl0VES0QsB74PnFnqREl7Am8BPhER2yJiDfDNouP/D3B5RCyIxNKI+PvOEiRpGvA64LMRsT0iHgJ+kD5fwV8jYn4kdRbXkgRHG4QcIKw/OBe4OSJeStd/RpdiJpK/5AsagVHp8t5A1y++vwP7FK2/WLTcVGK9cC0kfTotltkkaSNJrmNi1wRHRDNwPXBWWkT0PpIvy94opHE9SYDcW9LGwoekWGnPbs6dAdQCzxcdfxVJTgJgGkmg7a29gfURsaVoW9f32fXfYliheMoGF/+jWkVJGk5SXFMtqfDFUw/sIenwiHh4J5dYTfJlWWw68KddSMtxwGeBE4DHIyIvaQNJEU0pPyEJCn8FGiPinl7e8l3AGuApYA9gRUTM7ubYrsMurwSagYlpTqirlSTFauVcq9hqYLyk0UVBYjpJcZUNMc5BWKWdBuSAg0mKjeaQlMn/haTiemfmAwdIer+kGklnpNf6/S6kZTTQRlLmXiPpEmBMdwenASEPXEEvcg+S9pR0IfBF4OKIyJPUH2yW9FlJwyVVSzpU0tHpaS8CMwsV2hHxPHAzcIWkMZKqJO0n6fXp8T8APiPpKCX2lzSj6Fr7dvNMK4G7ga9KGibplcB5JMV6NsQ4QFilnUtSR/BsJK17XoiIF4BvAx/YWdFFRKwD3k5SobwO+Ffg7UXFVb1xE0kdxdMkxSrbSf4S78k1wGFAOX0UNkraBjxKUsl7ekTMTZ8jR1JvMgdYAbxE8iU/Nj33hvTnOkkPpMvnkFRoLyapmP8lMCW93g3Af5AU120hqdAen573VeDf0qKpz5RI5/tIKq5XA78GvhgRt5TxfDbIKMITBpntKknnABdExOsqnRaz3c05CLNdJGkESdPcqyudFrMsOECY7QJJbyapq3iRpBjHbNBxEZOZmZXkHISZmZU0aPpBTJw4MWbOnFnpZJiZDSiLFi16KSImldo3aALEzJkzWbhwYaWTYWY2oEjqdggWFzGZmVlJDhBmZlaSA4SZmZXkAGFmZiU5QJiZWUkOEGZmVpIDhJmZleQAYWY2gN24aBU/u+/ZTK7tAGFmNoD9+sHn+OWinU1bsmscIMzMBrCm1hzDaqszubYDhJnZALbdAcLMzEpJAkQ2X+UOEGZmA1guH9RWO0CYmVkX+YAqKZNrO0CYmQ1guXyQUXxwgDAzG8gigmrnIMzMrKsBW8Qk6RRJT0laKumiEvs/JWmxpEck3SppRtG+nKSH0s+8LNNpZjZQ5SOoyuibPLMpRyVVA1cCJwGrgAWS5kXE4qLDHgQaIqJR0j8BlwNnpPuaImJOVukzMxsM8hFoAOYgjgGWRsTyiGgBrgNOLT4gIm6PiMZ09V5gaobpMTMbdPLBgKyD2AcoHiBkVbqtO+cBfyxaHyZpoaR7JZ1W6gRJF6THLFy7du3LT7GZ2QCTj6Aqo1ZMmRUxAaWSHCUPlM4CGoDXF22eHhGrJe0L3Cbp0YhY1uliEVcDVwM0NDSUvLaZ2WCWzw/MIqZVwLSi9anA6q4HSToR+DzwzohoLmyPiNXpz+XAHcARGabVzGxAGqitmBYAsyXNklQHnAl0ao0k6QjgKpLgsKZo+zhJ9enyROBYoLhy28zMSIqYMhppI7sipohok3QhcBNQDcyNiMclXQYsjIh5wH8Co4Ab0izSsxHxTuAg4CpJeZIg9rUurZ/MzIxCHUQ2OYgs6yCIiPnA/C7bLilaPrGb8+4GDssybWZmg0E+GJB1EGZmlrF8PrtWTA4QZmYDWFIH4RyEmZl14SImMzPbQUTS/ctFTGZm1kkuXwgQzkGYmVmRND64DsLMzDrLp0VMnlHOzMw6SeODi5jMzKyznCupzcyslHy4ktrMzEqIfPLTAcLMzDrJu4jJzMxKaa+DcDNXMzMr5joIMzMryc1czcyspI6hNrK5vgOEmdkA9YXfPAZAbUZzjjpAmJkNULc+uQaAuhoHCDMzK8E5CDMzK6m22pXUZmZWglsxmZlZaW7FZGZmpWQUHxwgzMwGOhcxmZlZSZ5RzszMSho3oi6T69ZkclUzM8vcHiNq2WN4LYfuMzaT6zsHYWY2QFVJHDd7UnbXz+zKgKRTJD0laamki0rs/5SkxZIekXSrpBlF+86VtCT9nJtlOs3MBqK2XJ7qrEbqI8MAIakauBJ4C3Aw8D5JB3c57EGgISJeCfwSuDw9dzzwReBVwDHAFyWNyyqtZmYDUS4fmfWihmxzEMcASyNieUS0ANcBpxYfEBG3R0RjunovMDVdfjNwS0Ssj4gNwC3AKRmm1cxswGnNB9VV2X2NZxkg9gFWFq2vSrd15zzgj705V9IFkhZKWrh27dqXmVwzs4Ellw9qBmIRE6U790XJA6WzgAbgP3tzbkRcHRENEdEwaVJ2FTVmZv1NRJDLx8CsgyD5q39a0fpUYHXXgySdCHweeGdENPfmXDOzoaotnU1uoNZBLABmS5olqQ44E5hXfICkI4CrSILDmqJdNwEnSxqXVk6fnG4zMzM6phvNsg4is45yEdEm6UKSL/ZqYG5EPC7pMmBhRMwjKVIaBdygpK/4sxHxzohYL+lLJEEG4LKIWJ9VWs3MBppCDiLLOohMe1JHxHxgfpdtlxQtn9jDuXOBudmlzsxs4GrL5QEGbB2EmZllZKDXQZiZWUb6og7CAcLMbABqTYuYBmo/CDMzy0hHDsIBwszMimxvTXIQdTUuYjIzsyK/fyTpOzxl7LDM7uEAYWY2AP3PbUsB2MsBwszMir39lVMAmDpuRGb3KCtASJqRjpmEpOGSRmeWIjMzK8usiSMzvf5OA4Sk80km87kq3TQV+E2WiTIzs541teQYUVed6T3KyUH8C3AssBkgIpYAk7NMlJmZ9ayxnwSI5nRGOAAk1dDNvA5mZtY3GlvaGF6X6XB6ZQWIOyV9Dhgu6STgBuB3mabKzMx61JIL6qqzbWdUztUvAtYCjwIfIRmd9d+yTJSZmfUsnw8yjg89D/ctqRr4SUScBXw/26SYmVm5cpHtdKOwkxxEROSASemMcGZm1k/k80GVsg0Q5dRwPAP8TdI8YFthY0R8I6tEmZlZz/oiB1FOgFidfqoAd5AzM+sHcvmgutI5iIj4d4C093RExNZMU2RmZjuVzwdVlayDAJB0qKQHgceAxyUtknRIpqkyM7Me5SL7HEQ5jaSuBj4VETMiYgbwadyiycysonJ5Kp+DAEZGxO2FlYi4A8h2hCgzM+tRPircDyK1XNIXgGvT9bOAFdklyczMdqYvKqnLiT8fBiYBv0o/E4EPZZkoMzPrWV9UUpfTimkD8LFMU2FmZr3SLyqpJd0iaY+i9XGSbso0VWZm1qNcvsJDbaQmRsTGwkqao/B8EGZmFZSPftAPAshLml5YkTQDzwdhZlZRbf2kkvrzwF8lXSvpWuAu4OJyLi7pFElPSVoq6aIS+4+X9ICkNknv6bIvJ+mh9DOvnPuZmQ0FEUEElR+LKSL+JOlI4NXppk9GxEs7Oy8dKvxK4CRgFbBA0ryIWFx02LPAB4HPlLhEU0TM2dl9zMyGmlw+KcSpWB2EpBmSxgKkAWEbyZf9OWUO/30MsDQilqdTll4HnFp8QEQ8ExGPAPldfQAzs6EmFxUOEMD1pD2mJc0hmWr0WeBw4DtlXHsfYGXR+qp0W7mGSVoo6V5Jp5U6QNIF6TEL165d24tLm5kNXPn0T+pKzgcxPCJWp8tnAXMj4gpJVcBDZVy7VMp7U7k9PSJWS9oXuE3SoxGxrNPFIq4mGSuKhoYGV5yb2ZDQkYPI9j49Xb74C/5NwK0AEVFucdAqYFrR+lSSeSXKUghOEbEcuAM4otxzzcwGs0IdRNY5iJ4CxG2Srpf0LWAccBuApClASxnXXgDMljQrrbM4EyirNVLaGa8+XZ4IHAss7vksM7OhoRAgaipYB/EJkrGXngFeFxGt6fa9SJq+9igi2oALgZuAJ4DrI+JxSZdJeieApKMlrQJOB66S9Hh6+kHAQkkPA7cDX+vS+snMbMhqSyshajIuY+q2DiIigqTlUdftD5Z78YiYD8zvsu2SouUFJEVPXc+7Gzis3PuYmQ0l/SEHYWZm/VBbLg0QGecgHCDMzAaYtv6Sg5D09rRpq5mZ9QNtuUIdROWLmM4Elki6XNJBmabGzMx2qt/kICLiLJI+CMuAH0m6J+3BPDrTlJmZWUmthRxEVT+og4iIzcCNJK2apgDvAh6Q9NEM02ZmZiU0tyUBYlhtdab3KacO4h2Sfk3SUa4WOCYi3kIyJlOpUVjNzCxDn7guGe2ovrZC/SCKnA58MyLuKt4YEY2SPpxNsszMrDvPbWwCYFhNtjmIcuaDOKeHfbfu3uSYmVm5RtZXKEBI2kLn0VeVrouko/WYTFNmZmY9mjZ+RKbX72moDbdSMjPrh0YPq+HdR06ltlJjMXUlaTIwrLAeEc9mkiIzM+tRay5PfU32/ZfLacX0TklLgBXAnSSju/4x43SZmVk3WtrymeceoLx+EF8CXg08HRGzgBOAv2WaKjMzKymXD/IBdf0hBwG0RsQ6oEpSVUTcDszJOF1mZlZCS9pJri9yEOXUQWyUNAq4C/ippDVAW7bJMjOzUlrSYTb6Sw7iVKAJ+CTwJ5Ixmd6RZaLMzKy0Qg6iLuORXKG8jnLbACSNAX6XeYrMzKxbfZmD2GmAkPQR4DKSXESejg5z+2abNDMz66q1n9VBfAY4JCJeyjoxZmbWve2tOT768weB/lMHsQxozDohZmbWs2/ftpRHn9sEZD8XBJSXg7gYuFvSfUBzYWNEfCyzVJmZ2Q6+ffvS9uWMJ5MDygsQV5HMBfEoSR2EmZlVWJX6QSsmoC0iPpV5SszMrGx9EB/KqoO4PZ2Deoqk8YVP5ikzM7Nu9UWAKCcH8f7058VF29zM1cysj+0xopaNja0AiH5QxJQO0GdmZhU2bdwINjYmrZj6RQ5CUi3wT8Dx6aY7gKsiojXDdJmZWRetuY52QoftMzbz+5VTB/Fd4CjgO+nnqHTbTkk6RdJTkpZKuqjE/uMlPSCpTdJ7uuw7V9KS9HNuOfczMxvMcvngbYdN4ZmvvY0Jo+ozv185dRBHR8ThReu3SXp4ZydJqgauBE4CVgELJM2LiMVFhz0LfJCkt3bxueOBLwINJPUdi9JzN5SRXjOzQaktH1T3RQeIVDk5iJyk/QorkvYFcmWcdwywNCKWR0QLcB3JyLDtIuKZiHiEHftXvBm4JSLWp0HhFuCUMu5pZjZoteby1PTBKK4F5eQg/i9JU9flJAP1zQA+VMZ5+wAri9ZXAa8qM12lzt2nzHPNzAalXD6o6cMcRDmtmG6VNBt4BUmAeDIimndyGumxO1yuzHSVda6kC4ALAKZPn17mpc3MBqbWXFDTB6O4FpR7p6OAQ4HDgTMknVPGOauAaUXrU4HVZd6vrHMj4uqIaIiIhkmTJpV5aTOzgSmXz/evHISka4H9gIfoqHsI4JqdnLoAmC1pFvAccCYdne525ibgK5LGpesn07mjnpnZkNOW69tK6nLqIBqAgyOi3OIhACKiTdKFJF/21cDciHhc0mXAwoiYJ+lo4NfAOOAdkv49Ig6JiPWSvkQSZAAui4j1vbm/mdlg05aPPpkoqKCcAPEYsBfwfG8vHhHzgfldtl1StLyApPio1Llzgbm9vaeZ2WDVls/3uxzERGCxpPvpPB/EOzNLlZmZ7aAtH9T2swBxadaJMDOznuXyQQRU98FMcgXlNHO9s3hd0rEklc13lj7DzMx2t7Z80p+4v3WUQ9IckqDwXmAFcGOWiTIzs87ackk7oX7RzFXSASRNU98HrAN+ASgi3thHaTMzs1RhJNe6mv5RxPQk8BfgHRGxFEDSJ/skVWZm1klzWxIg6muq++yePYWidwMvkIzD9H1JJ1B6CAwzM8tYc2shQPSDoTYi4tcRcQZwIMkkQZ8E9pT0XUkn91H6zMwM2NKczNFWX9sPAkRBRGyLiJ9GxNtJOrU9BOww+Y+ZmWVn5fomAPYcM6zP7tmrUJTOz3BVRLwpqwSZmdmOtjW3ATB5dPYzyRX0XV7FzMx2WWNrMlbq8Lr+UUltZmb9xPaWJEAMq3WAMDOzIi2FfhD9cMIgMzPrIxHBor+vp3iWhVYHCDOzoe3e5eu4YdEq3v3de7h+4cr27S1tyWxyVf1hqA0zM+tbL2zazplX39u+/tkbH+WMo6cDSQ6iLycLAucgzMz6ja1pZ7hiqzY0AtCaiz4dhwkcIMzM+o3N29t22HbpvMVAMhaTcxBmZkPU5qYdcxD3r1gHJEVMdX04FwQ4QJiZ9RulchCj6pOq4tZcnloXMZmZDU0P/H3DDtumTxgBJK2Y+rKJKzhAmJn1Gz+++5lO69PHj6DQFcKtmMzMrN308SPae1C35MJFTGZmlhhWW90+UVBLW4565yDMzIaev6/b1r48cVQypHd9TRXNbckgfa25oLbGrZjMzIacxas3ty/f+qnXc+/FJ6QBIslBVKIOwkNtmJn1A1KSO3jfMdMZO6KWsdRSX9sRINyKycxsiGpqTfpAnH/crPZtw2tr2NTUSmsuT4v7QZiZDU1NLUlOYURdR8HOvpNG0tKW56WtzWlP6kEUICSdIukpSUslXVRif72kX6T775M0M90+U1KTpIfSz/eyTKeZWaU1tiQ5iOIpRSeMrANg9camihQxZVYHIakauBI4CVgFLJA0LyIWFx12HrAhIvaXdCbwdeCMdN+yiJiTVfrMzPqTpnRK0RFFASKtluC8nyykShpUrZiOAZZGxPKIaAGuA07tcsypwE/S5V8CJ6hQU2NmNoQ0tuaorVanlkp7jR0OwMbGVloH2Wiu+wAri9ZXpdtKHhMRbcAmYEK6b5akByXdKem4UjeQdIGkhZIWrl27dvem3sysDzW15BheW91p25xpewBw0sF70tiaY2Rd3zY8zTJAlMoJRJnHPA9Mj4gjgE8BP5M0ZocDI66OiIaIaJg0adLLTrCZWaU0trR1qn8oaJgxjmVrt5LLB3vvMbxP05RlgFgFTCtanwqs7u4YSTXAWGB9RDRHxDqAiFgELAMOyDCtZmYV1dSa79SCqWDiqHpe2LQdgJpBNB/EAmC2pFmS6oAzgXldjpkHnJsuvwe4LSJC0qS0khtJ+wKzgeUZptXMrKKaWtp2KGICmDi6jsa0AnvQtGKKiDZJFwI3AdXA3Ih4XNJlwMKImAf8ELhW0lJgPUkQATgeuExSG5AD/jEi1meVVjOzSmtsyXVqwVQwbkRd+3Jf5yAyrfGIiPnA/C7bLila3g6cXuK8G4Ebs0ybmVml5fLBf/zhCT507EzWb2th6rgd6xiGFeUqaqoGSQ7CzMx69sTzm5n7txU8vGoja7Y00zBz3A7HFBc71Q6iOggzsyFje2uO1nRyn3IVBuJrasmxtbmNkfU7/s1e3LJpMPWDMDMbEprbchz4hT/xge/f16vzNmxrAWBkfTUtbfmS/RyKcxDF9RF9wQHCzKwMmxpbaWkrnUP446MvAHD/M71rS/Pfty0BoC4dpbVUDqK6qqNYafwoBwgzsz63vTXX4/7DL7uZj1y7sOS+lesbd+mej6zaBMDo+loARpZoxZSPjv7F40bU7tJ9dpUDhJkNeSvXN3LgF/7EDQtX9njc7U+VHtLnyRe2tC9HdB0wAp7b2MQlv32s2xzItnQk1xElchBvOXQKH33T/lxx+uElO9Jlya2YzGzIW7Z2KwC/euA5Tm+Y1uOxjS1tO3xRb2hsaV9+aWsLk0bXd9p/7NduA2D2nqM5+9UzADoFi83bkwBRKgdRV1PFp09+RbmPsls5B2FmQ966rckX/KK/byi5vzhXcEeJXMTW5rb25V8uWtXtfdZs3t6+vKmptX15S7rc1zmEnXGAMLMhb+3WZgBacnly+R2LiIq3FecWIAkOhboEgK//6cn21kldFfdi6BQg0gAzqkQRUyU5QJjZkLcuDRAAS9Zs2WF/rigHsX5r5y//wkB6xe5a0jmXcdCUZDDq7UXFSp0CxPY0B1G/YxFTJTlAmNmQcsE1C/nq/Cc6bWsqasH0fJcv/It/9Qg/v+/Z9vV1XXIHhS/6hhkdvaA/ft1DnY7Z2tya/uwoinqpKChtb00CR1/P97Az/Ss1ZmYZ2trcxs2LXwTgs6ccSFXax6CppeMv+8bmzs1df35/55ZNK17aBsCz6xoZN7KWzelf/59720Fcd/+zXL8wqYNoy+WpSXs+b0krobcVBYg1W5rpaszw/vWV7ByEmQ1Kz29q4ku/X8yjRfUDJ1xxR/tyc1Fxz/a2XHtntUKTU6Dk0BlLXkyKoI7/z9s5/Xv3sDnNQYwZVsvl7zmcNx+yJ5C0iIKkgrsQILZu77h2rsu1R9RVu5LazKwvXHHz0/zwryt4x7f/2r5t/MiO5qfNbbn21knNrTkmjkx6KTcW/ZVfXE8ASSXymi3N7fUOT76whbVpTmDs8KQT2yF7jwXgX298hN89vJrGllx7JfeWogDRtS58/Mi+7SVdDgcIMxsw7lu+jq+k9QcR0d5/AZK/9otzC6Wamx4xfY/25TufXsucy25hxUvbaGrNMWFUEjy2tXQUMd30+Audzp88up5cBLc88WL7tqdf3MLw2ur2Xs5nHN3Rj+KjP3+Qb926pH29UBwFHT2kTz9qKkD7/fsTBwgzGzDOuPperr5rOVub27jj6bWccMWd/O7hZCbjQm5h5kV/6HbYjOLOaR+/7iE2NbVy19Nr2d6aZ8zwGuqqq9jc1Mp/37qEs394H1fc/DQA7ztmOgBvPHAyEUmgKrh+4SqaWnPt9Q17jhnW6Z5X35VMhjmirro9B7F0zdb2znGFbX08kndZ+leBl5lZGRasWM/jq5PcwgPPbuAdh+/NXU93NC0tHvoCksrh1RubSuYqmlpzbN3exviRI9h7j2Gs2tDEHx59HoDR9TW8+8ipfPUfDuOr/3AY/5PmBn7/yPO9TvPsPUezYu1WLvntY1xzz9/btxcG4Htw5cZeXzNrzkGYWb/x/KYmfvPgczs97kM/XsD8dATVW59YA3TuhfyNW5K//AtDVxzyxZs46Zt3lbzWms3NrHhpG/tOHMnUcSPagwMkHdheNWt8+3p1N3/m/9Mb9uu0fvl7XrnDMftNGsm2llyn4ADwsTfNBuDY/SaWvHYlOUCYWb/xoR8t4BO/eKhTH4GCh7r8hV1oYfTs+kYigrZ8nvq0JVIhN1Fcn9CdRc9uoCWX5xV7jS455eeconqLmqKhtz9z8gHty1PGdi5Wem/DtPbWTAXTxo0o2Ut70uh6fvyho/ne2UftNK19zQHCzPqF5rZce9HQrx5Y1Wn8o6vvWsZpV/6t0/FL1nRUUJ8z937ueGotE7q0BDr3NTN2uM8bXjGpffngKWN4OA08+08exbTxI3Y4ftbEke3LVeoIEG88cHL78vGzJ9HVN947h2G1HV+xE0eXroSuErzhFZP73TAb4ABhZv3EbWlREcBX5j/JrIvnc8+yddy97CW+Mv/J9n3FPZY/+NqZAPxlyUsArC7qBX3MrPH88xv356qzj+LmTx7P3y56EwBHTOs4f/KYji/t8SPrOgWDy9/9Su74zBs6TfO5ragT3eTRHbmGmUXnFYysr+HTJ3WMwtpdHbTUD2unU/0vZJnZoLdyfSO/XLSKj75p//bWP9+5Y9kOx73v+/fusO1TJx/A+9OpPU+dszc/vvuZ9n0/O/9V7DVmGJPHDGv/i/zNh+zVvv/+z53A+JF1fPPPSR3FhKJ+EaOH1bbP6DZuRC3vPXrHYb+Xv9SRayn0e9h/8qhun/P84/dlRH01qzc2MWdaR1HV+cfN4vt/WdHtef2FA4SZ9bnTv3cPL2zezqH7jGVUfQ2jh9Xw6HObdnrel047lCljO+oJXjm140v3e2cdxWt3UtE7uagJ6tjhtZ06wo2qr+H42RP50QeP5vgDdiniYkoAAAiQSURBVCwyApg5oSOnUFdTxTUfPobD9hnb4z0/8Kodi7nOfe1MBwgzs1JeSOdFOP+aHafw/NMnjuPZdY3sO2kkP79/JT/8a/JFessnj2fWxJG0FVX0VleJmRNG8OLmZk45dK8drtWd2z/zBkbWVbNqYxN/Tju9FeZ+Lq5b6Oqjb9qfa+55htfsNwGg20DSnbrqKkbWVzN13AgOmjKGxqJhPfojBwgz61OP9ZBTeNsrp3DgXmM4cK9keOzPvfUg9hxTzxkN0xmb9lSu6TIi9i2fej0lZvnsUaGuYfKYYXzgVdNpLKO1U3LvKh685OTe3azIw188mUKVwx8/ftwuX6evOECYWZ+6Ku1Z/OFjZzH3b52LWeqrO7ebqa4SFxzfuY8BwA3/+Jr2OoDa6pfX1uY/3nXYyzq/N4aXmFK0P3MrJjPrU63pcBefe+uBQNLUtND/IFdmVuDomeM5YM/R2STQ2jkHYWa7TS4f7WX5XeXzweLnN/Onx1/gxIMmU1NdxdNffgvVVeIvS9bywR8t6HYMJauMTAOEpFOAbwHVwA8i4mtd9tcD1wBHAeuAMyLimXTfxcB5QA74WETclGVazWzXbdjWwhFfuqV9feG/nciIumqWvLiVupoqZk0cScOX/9w+o9rr08rdwhwMr953Ame/egbnvW5W3yfeupVZgJBUDVwJnASsAhZImhcRi4sOOw/YEBH7SzoT+DpwhqSDgTOBQ4C9gT9LOiAi/OeFWT+zdkvzDq2RGr785x7PKYyOWjCstpovnXbobk+bvTxZ5iCOAZZGxHIASdcBpwLFAeJU4NJ0+ZfAt5V0KzwVuC4imoEVkpam17tndydyY2ML7/rO3bv7smWJ3ja92F33rchd6XVLk912X6Ji994VuyutPXXQ7XFft31+k/MikqKkfCSfFzd3TJjz/86cw3/d9BSPr968wzkAj1x6MmOG1fbqOaxysgwQ+wDFk7muAl7V3TER0SZpEzAh3X5vl3P36XoDSRcAF0BSRtXjb3039gBu7/VZZlbSpfDGnvZ/vY/SYbtFlgGi1Ld117+NujumnHOJiKuBqwEaGhqChTt2ujEzsx708Id1ls1cVwHFg5lMBVZ3d4ykGmAssL7Mc83MLENZBogFwGxJsyTVkVQ6z+tyzDzg3HT5PcBtkRTMzwPOlFQvaRYwG7g/w7SamVkXmRUxpXUKFwI3kTRznRsRj0u6DFgYEfOAHwLXppXQ60mCCOlx15NUaLcB/+IWTGZmfUuVakmzuzU0NMRC10GYmfWKpEUR0VBqn4faMDOzkhwgzMysJAcIMzMryQHCzMxKGjSV1JLWAn9/GZeYCLy0m5IzUPkd+B2A3wEMrXcwIyJKTo03aALEyyVpYXc1+UOF34HfAfgdgN9BgYuYzMysJAcIMzMryQGiw9WVTkA/4HfgdwB+B+B3ALgOwszMuuEchJmZleQAYWZmJQ35ACHpFElPSVoq6aJKpydLkp6R9KikhyQtTLeNl3SLpCXpz3Hpdkn67/S9PCLpyMqmftdImitpjaTHirb1+pklnZsev0TSuaXu1V918w4ulfRc+rvwkKS3Fu27OH0HT0l6c9H2Aft/RdI0SbdLekLS45I+nm4fUr8LvRYRQ/ZDMgz5MmBfoA54GDi40unK8HmfASZ22XY5cFG6fBHw9XT5rcAfSWb3ezVwX6XTv4vPfDxwJPDYrj4zMB5Ynv4cly6Pq/Szvcx3cCnwmRLHHpz+P6gHZqX/P6oH+v8VYApwZLo8Gng6fdYh9bvQ289Qz0EcAyyNiOUR0QJcB5xa4TT1tVOBn6TLPwFOK9p+TSTuBfaQNKUSCXw5IuIukrlGivX2md8M3BIR6yNiA3ALcEr2qd89unkH3TkVuC4imiNiBbCU5P/JgP6/EhHPR8QD6fIW4AmSee6H1O9Cbw31ALEPsLJofVW6bbAK4GZJiyRdkG7bMyKeh+Q/ETA53T6Y301vn3mwvosL0+KTuYWiFYbAO5A0EzgCuA//LvRoqAeIUrN1D+Z2v8dGxJHAW4B/kXR8D8cOtXcD3T/zYHwX3wX2A+YAzwNXpNsH9TuQNAq4EfhERGzu6dAS2wbNeyjXUA8Qq4BpRetTgdUVSkvmImJ1+nMN8GuSYoMXC0VH6c816eGD+d309pkH3buIiBcjIhcReeD7JL8LMIjfgaRakuDw04j4Vbp5yP8u9GSoB4gFwGxJsyTVkcyJPa/CacqEpJGSRheWgZOBx0iet9AS41zgt+nyPOCctDXHq4FNhaz4INDbZ74JOFnSuLQo5uR024DVpT7pXSS/C5C8gzMl1UuaBcwG7meA/1+RJOCHwBMR8Y2iXUP+d6FHla4lr/SHpLXC0yQtND5f6fRk+Jz7krQ8eRh4vPCswATgVmBJ+nN8ul3Alel7eRRoqPQz7OJz/5ykCKWV5K+/83blmYEPk1TYLgU+VOnn2g3v4Nr0GR8h+TKcUnT859N38BTwlqLtA/b/CvA6kqKgR4CH0s9bh9rvQm8/HmrDzMxKGupFTGZm1g0HCDMzK8kBwszMSnKAMDOzkhwgzMyspJpKJ8BsoJFUaBoJsBeQA9am640R8dqKJMxsN3MzV7OXQdKlwNaI+K9Kp8Vsd3MRk9luJGlr+vMNku6UdL2kpyV9TdIHJN2vZE6O/dLjJkm6UdKC9HNsZZ/ArIMDhFl2Dgc+DhwGnA0cEBHHAD8APpoe8y3gmxFxNPDudJ9Zv+A6CLPsLIh0/CpJy4Cb0+2PAm9Ml08EDk6GCgJgjKTRkcxZYFZRDhBm2WkuWs4Xrefp+L9XBbwmIpr6MmFm5XARk1ll3QxcWFiRNKeCaTHrxAHCrLI+BjSkM7stBv6x0gkyK3AzVzMzK8k5CDMzK8kBwszMSnKAMDOzkhwgzMysJAcIMzMryQHCzMxKcoAwM7OS/j+YweuYHgW2qgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot([x for x in range(a.shape[0])], a)\n",
    "plt.axhline(y=b.mean() + 5 * b.std(), color='r', linewidth=1)\n",
    "plt.title('Anomaly Detection')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Anomaly Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00010550405386311468"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mean() + 5 * b.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx = np.max(np.where(a < b.mean() + 5 * b.std())[0]); start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ = a[:start_idx]\n",
    "np.where(a_ > b.mean() + 5 * b.std())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "USAD_test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
