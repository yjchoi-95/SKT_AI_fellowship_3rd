{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etniX_KTlJ5U"
   },
   "source": [
    "# USAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3jM0qLU8MgZ"
   },
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6u1DGKsAlLF-"
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from usad import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1crx5rGP9ONf"
   },
   "source": [
    "## EDA - Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfSj4FYL9W8Y"
   },
   "source": [
    "### Normal period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "XeDLxV_r1G9n",
    "outputId": "576538dd-64f2-46fa-8e6f-6c2ffdebad15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2803, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"C:\\\\Users\\\\PC\\\\OneDrive\\\\문서\\\\GitHub\\\\datasets\\\\\"\n",
    "\n",
    "#Read data\n",
    "data = pd.read_csv(data_path + \"Bearing1_1_top5_result.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxFNH5kU9hIE"
   },
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Mfxj4Uxn9kv4"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "x = data.values\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "scaled_data = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "mQ6_U4jn9nlw",
    "outputId": "f1cc1bd6-f1cc-4764-b1cc-2fd989ac4918"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025027</td>\n",
       "      <td>0.014330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021423</td>\n",
       "      <td>0.015064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.025027  0.014330\n",
       "1  0.021423  0.015064"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXJi503b-j_d"
   },
   "source": [
    "### Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vyplttZa-BRN"
   },
   "outputs": [],
   "source": [
    "window_size=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dzGJMp6Y-BN5",
    "outputId": "2949d278-1313-442c-f06b-275a8c6c6578"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2791, 12, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows_normal=scaled_data.values[np.arange(window_size)[None, :] + np.arange(scaled_data.shape[0]-window_size)[:, None]]\n",
    "windows_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k70ZFxGs-_7m"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 100\n",
    "hidden_size = 10\n",
    "\n",
    "w_size=windows_normal.shape[1]*windows_normal.shape[2]\n",
    "z_size=windows_normal.shape[1]*hidden_size\n",
    "\n",
    "windows_normal_train = windows_normal[:400]\n",
    "windows_normal_test = windows_normal[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import math\n",
    "\n",
    "class Dataloader(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, shuffle=False):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle=shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    # batch 단위로 직접 묶어줘야 함\n",
    "    def __getitem__(self, idx):\n",
    "        # sampler의 역할(index를 batch_size만큼 sampling해줌)\n",
    "        indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "\n",
    "        batch_x = [self.x[i] for i in indices]\n",
    "        batch_y = [self.y[i] for i in indices]\n",
    "\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n",
    "    # epoch이 끝날때마다 실행\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.x))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_normal_train_re = windows_normal_train.reshape(windows_normal_train.shape[0], w_size)\n",
    "windows_normal_test_re = windows_normal_test.reshape(windows_normal_test.shape[0], w_size)\n",
    "windows_normal_re = windows_normal.reshape(windows_normal.shape[0], w_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Dataloader(windows_normal_train_re,windows_normal_train_re,BATCH_SIZE)\n",
    "test_loader = Dataloader(windows_normal_test_re,windows_normal_test_re,BATCH_SIZE)\n",
    "whole_loader = Dataloader(windows_normal_re,windows_normal_re,BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* USAD tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model) :\n",
    "    def __init__(self, in_size, latent_size):\n",
    "        super().__init__()\n",
    "        self.model = tf.keras.Sequential([\n",
    "            tf.keras.Input(shape = (in_size)),\n",
    "            tf.keras.layers.Dense(int(in_size/2), activation = \"relu\"),\n",
    "            tf.keras.layers.Dense(int(in_size/4), activation = \"relu\"),\n",
    "            tf.keras.layers.Dense(latent_size, activation = \"relu\")\n",
    "        ])\n",
    "    \n",
    "    def call(self, x) :\n",
    "        z = self.model(x)\n",
    "        return z\n",
    "    \n",
    "class Decoder(tf.keras.Model) :\n",
    "    def __init__(self, latent_size, out_size):\n",
    "        super().__init__()\n",
    "        self.model = tf.keras.Sequential([\n",
    "            tf.keras.Input(shape = (latent_size)),\n",
    "            tf.keras.layers.Dense(int(out_size/4), activation = \"relu\"),\n",
    "            tf.keras.layers.Dense(int(out_size/2), activation = \"relu\"),\n",
    "            tf.keras.layers.Dense(out_size, activation = \"sigmoid\")\n",
    "        ])\n",
    "    \n",
    "    def call(self, x) :\n",
    "        w = self.model(x)\n",
    "        return w\n",
    "    \n",
    "class UsadModel(tf.keras.Model):\n",
    "    def __init__(self, w_size, z_size, alpha = .5, beta = .5):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(w_size, z_size)\n",
    "        self.decoder1 = Decoder(z_size, w_size)\n",
    "        self.decoder2 = Decoder(z_size, w_size)\n",
    "        \n",
    "        self.latent_vector = self.encoder(self.encoder.model.inputs)\n",
    "        self.ae_output1 = self.decoder1(self.latent_vector)\n",
    "        self.ae_output2 = self.decoder2(self.latent_vector)\n",
    "\n",
    "        self.ae_model1 = tf.keras.Model(inputs = self.encoder.model.inputs, outputs = self.ae_output1)\n",
    "        self.ae_model2 = tf.keras.Model(inputs = self.encoder.model.inputs, outputs = self.ae_output2)\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        \n",
    "        self.alpha, self.beta = alpha, beta\n",
    "        \n",
    "    def evaluate(self, val_loader, n):\n",
    "        outputs = [self.validation_step(batch, n) for batch in val_loader]\n",
    "        return self.validation_epoch_end(outputs)\n",
    "    \n",
    "    def testing(self, test_loader):\n",
    "        results=[]\n",
    "        for batch, _ in test_loader:\n",
    "            w1=self.ae_model1(batch)\n",
    "            w2=self.ae_model2(w1)\n",
    "            results.append(self.alpha*np.mean((batch-w1).numpy()**2, axis = 1)+self.beta*np.mean((batch-w2).numpy()**2, axis = 1))\n",
    "        return results\n",
    "        \n",
    "    def call(self, x):\n",
    "        z = self.encoder(x)\n",
    "        w1 = self.decoder1(z)\n",
    "        w2 = self.decoder2(z)\n",
    "        w3 = self.decoder2(self.encoder(w1))\n",
    "        return w1, w2, w3\n",
    "    \n",
    "    def loss_fn(self, batch, n) :\n",
    "        loss1 = 1/n*tf.reduce_mean(tf.square(batch-self.w1)) + (1-1/n)*tf.reduce_mean(tf.square(batch-self.w3))\n",
    "        loss2 = 1/n*tf.reduce_mean(tf.square(batch-self.w2)) + (1-1/n)*tf.reduce_mean(tf.square(batch-self.w3))\n",
    "        \n",
    "        return loss1, loss2\n",
    "    \n",
    "    def training(self, train_loader, val_loader, num_epochs):\n",
    "        for n in range(num_epochs): \n",
    "            n += 1\n",
    "            \n",
    "            loss1_list, loss2_list = [], []\n",
    "            self.history = []\n",
    "            \n",
    "            # Iterate over the batches of a dataset.\n",
    "            for x_batch_train, y_batch_train in train_loader:\n",
    "                with tf.GradientTape() as ae1_tape, tf.GradientTape() as ae2_tape:\n",
    "                    self.z = self.encoder(x_batch_train)\n",
    "                    self.w1 = self.decoder1(self.z)\n",
    "                    self.w2 = self.decoder2(self.z)\n",
    "                    self.w3 = self.decoder2(self.encoder(self.w1))\n",
    "\n",
    "                    # Loss value for this minibatch\n",
    "                    loss1, loss2 = self.loss_fn(x_batch_train, n)\n",
    "                    \n",
    "                    # Add extra losses created during this forward pass:\n",
    "                    #loss_value += sum(model.losses)\n",
    "\n",
    "                grads_ae1 = ae1_tape.gradient(loss1, self.ae_model1.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads_ae1, self.ae_model1.trainable_weights))\n",
    "                grads_ae2 = ae2_tape.gradient(loss2, self.ae_model2.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads_ae2, self.ae_model2.trainable_weights))\n",
    "                loss1_list.append(loss1)\n",
    "                loss2_list.append(loss2)\n",
    "                \n",
    "            #print(\"Epoch [{}], train_loss1: {:.4f}, train_loss2: {:.4f}\".format(n, np.mean(loss1_list), np.mean(loss2_list)))\n",
    "            result = self.evaluate(val_loader, n)\n",
    "            self.epoch_end(n, result)\n",
    "            self.history.append(result)\n",
    "            \n",
    "    def validation_step(self, batch, n):\n",
    "        z = self.encoder(batch)\n",
    "        w1 = self.decoder1(z)\n",
    "        w2 = self.decoder2(z)\n",
    "        w3 = self.decoder2(self.encoder(w1))\n",
    "        loss1 = 1/n*tf.reduce_mean(tf.square(batch-w1)) + (1-1/n)*tf.reduce_mean(tf.square(batch-w3))\n",
    "        loss2 = 1/n*tf.reduce_mean(tf.square(batch-w2)) + (1-1/n)*tf.reduce_mean(tf.square(batch-w3))\n",
    "        \n",
    "        return {'val_loss1': loss1, 'val_loss2': loss2}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses1 = [x['val_loss1'] for x in outputs]\n",
    "        epoch_loss1 = tf.reduce_mean(batch_losses1)\n",
    "        batch_losses2 = [x['val_loss2'] for x in outputs]\n",
    "        epoch_loss2 = tf.reduce_mean(batch_losses2)\n",
    "        return {'val_loss1': epoch_loss1.numpy(), 'val_loss2': epoch_loss2.numpy()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss1: {:.4f}, val_loss2: {:.4f}\".format(epoch, result['val_loss1'], result['val_loss2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Encoder.call of <__main__.Encoder object at 0x0000017FEEAB7788>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Encoder.call of <__main__.Encoder object at 0x0000017FEEAB7788>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017FEEA8B888>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017FEEA8B888>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017FEEA8BDC8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017FEEA8BDC8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "Epoch [1], val_loss1: 0.2116, val_loss2: 0.2126\n",
      "Epoch [2], val_loss1: 0.1970, val_loss2: 0.1961\n",
      "Epoch [3], val_loss1: 0.1603, val_loss2: 0.1552\n",
      "Epoch [4], val_loss1: 0.1195, val_loss2: 0.1136\n",
      "Epoch [5], val_loss1: 0.0825, val_loss2: 0.0784\n",
      "Epoch [6], val_loss1: 0.0544, val_loss2: 0.0539\n",
      "Epoch [7], val_loss1: 0.0416, val_loss2: 0.0439\n",
      "Epoch [8], val_loss1: 0.0339, val_loss2: 0.0370\n",
      "Epoch [9], val_loss1: 0.0200, val_loss2: 0.0218\n",
      "Epoch [10], val_loss1: 0.0076, val_loss2: 0.0079\n",
      "Epoch [11], val_loss1: 0.0060, val_loss2: 0.0056\n",
      "Epoch [12], val_loss1: 0.0055, val_loss2: 0.0055\n",
      "Epoch [13], val_loss1: 0.0056, val_loss2: 0.0056\n",
      "Epoch [14], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [15], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [16], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [17], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [18], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [19], val_loss1: 0.0058, val_loss2: 0.0059\n",
      "Epoch [20], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [21], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [22], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [23], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [24], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [25], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [26], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [27], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [28], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [29], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [30], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [31], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [32], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [33], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [34], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [35], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [36], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [37], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [38], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [39], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [40], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [41], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [42], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [43], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [44], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [45], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [46], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [47], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [48], val_loss1: 0.0059, val_loss2: 0.0059\n",
      "Epoch [49], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [50], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [51], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [52], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [53], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [54], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [55], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [56], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [57], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [58], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [59], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [60], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [61], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [62], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [63], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [64], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [65], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [66], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [67], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [68], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [69], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [70], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [71], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [72], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [73], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [74], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [75], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [76], val_loss1: 0.0058, val_loss2: 0.0058\n",
      "Epoch [77], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [78], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [79], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [80], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [81], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [82], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [83], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [84], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [85], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [86], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [87], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [88], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [89], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [90], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [91], val_loss1: 0.0057, val_loss2: 0.0057\n",
      "Epoch [92], val_loss1: 0.0056, val_loss2: 0.0056\n",
      "Epoch [93], val_loss1: 0.0056, val_loss2: 0.0056\n",
      "Epoch [94], val_loss1: 0.0056, val_loss2: 0.0056\n",
      "Epoch [95], val_loss1: 0.0056, val_loss2: 0.0056\n",
      "Epoch [96], val_loss1: 0.0056, val_loss2: 0.0056\n",
      "Epoch [97], val_loss1: 0.0056, val_loss2: 0.0056\n",
      "Epoch [98], val_loss1: 0.0056, val_loss2: 0.0056\n",
      "Epoch [99], val_loss1: 0.0056, val_loss2: 0.0056\n",
      "Epoch [100], val_loss1: 0.0056, val_loss2: 0.0056\n"
     ]
    }
   ],
   "source": [
    "model_usad = UsadModel(w_size, z_size)\n",
    "model_usad.training(train_loader, test_loader, N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model_usad.testing(whole_loader)\n",
    "a = np.concatenate([np.stack(a[:-1]).flatten(), a[-1].flatten()])\n",
    "b = model_usad.testing(train_loader)\n",
    "b = np.concatenate([np.stack(b[:-1]).flatten(), b[-1].flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot([x for x in range(a.shape[0])], a)\n",
    "plt.axhline(y=b.mean() + 5 * b.std(), color='r', linewidth=1)\n",
    "plt.title('Anomaly Detection')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Anomaly Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003685270348796621"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mean() + 5 * b.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1540"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.where(a < b.mean() + 5 * b.std())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ = a[:1541]\n",
    "np.where(a_ > b.mean() + 5 * b.std())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly gap maximize net\n",
    "\n",
    "* 제안 아이디어 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UsadModel_AGM(tf.keras.Model):\n",
    "    def __init__(self, w_size, z_size, alpha = .5, beta = .5):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(w_size, z_size)\n",
    "        self.decoder1 = Decoder(z_size, w_size)\n",
    "        self.decoder2 = Decoder(z_size, w_size)\n",
    "        \n",
    "        self.latent_vector = self.encoder(self.encoder.model.inputs)\n",
    "        self.ae_output1 = self.decoder1(self.latent_vector)\n",
    "        self.ae_output2 = self.decoder2(self.latent_vector)\n",
    "\n",
    "        self.ae_model1 = tf.keras.Model(inputs = self.encoder.model.inputs, outputs = self.ae_output1)\n",
    "        self.ae_model2 = tf.keras.Model(inputs = self.encoder.model.inputs, outputs = self.ae_output2)\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        \n",
    "        self.alpha, self.beta = alpha, beta\n",
    "        \n",
    "    def evaluate(self, val_loader, n):\n",
    "        outputs = [self.validation_step(batch, n) for batch in val_loader]\n",
    "        return self.validation_epoch_end(outputs)\n",
    "\n",
    "    def testing(self, test_loader):\n",
    "        results=[]\n",
    "        for batch, _ in test_loader:\n",
    "            w1=self.ae_model1(batch)\n",
    "            w2=self.ae_model2(w1)\n",
    "            results.append(self.alpha*np.mean((batch-w1).numpy()**2, axis = 1)+self.beta*np.mean((batch-w2).numpy()**2, axis = 1))\n",
    "        return results\n",
    "        \n",
    "    def call(self, x):\n",
    "        z = self.encoder(x)\n",
    "        w1 = self.decoder1(z)\n",
    "        w2 = self.decoder2(z)\n",
    "        w3 = self.decoder2(self.encoder(w1))\n",
    "        return w1, w2, w3\n",
    "    \n",
    "    def loss_fn(self, batch, n) :\n",
    "        loss1 = 1/n*tf.reduce_mean(tf.square(batch-self.w1)) + (1-1/n)*tf.reduce_mean(tf.square(batch-self.w3))\n",
    "        loss2 = 1/n*tf.reduce_mean(tf.square(batch-self.w2)) + (1-1/n)*tf.reduce_mean(tf.square(batch-self.w3))\n",
    "        \n",
    "        return loss1, loss2\n",
    "    \n",
    "    def training(self, train_loader, val_loader, num_epochs):\n",
    "        self.history = []\n",
    "        \n",
    "        for n in range(num_epochs): \n",
    "            n += 1\n",
    "            \n",
    "            loss1_list, loss2_list, loss3_list = [], [], []\n",
    "            \n",
    "            # Iterate over the batches of a dataset.\n",
    "            for x_batch_train, y_batch_train in train_loader:\n",
    "                with tf.GradientTape() as ae1_tape, tf.GradientTape() as ae2_tape, tf.GradientTape() as pg_tape:\n",
    "                    self.z = self.encoder(x_batch_train)\n",
    "                    self.w1 = self.decoder1(self.z)\n",
    "                    self.w2 = self.decoder2(self.z)\n",
    "                    self.w3 = self.decoder2(self.encoder(self.w1))\n",
    "                    \n",
    "                    real_recon1 = x_batch_train-self.w1\n",
    "                    real_recon2 = x_batch_train-self.w2\n",
    "                    fake_recon = x_batch_train-self.w3\n",
    "\n",
    "                    # Loss value for this minibatch\n",
    "                    loss1, loss2 = self.loss_fn(x_batch_train, n)\n",
    "                    \n",
    "                    pg_advantage = tf.stop_gradient(tf.reduce_mean(tf.square(fake_recon))-tf.reduce_mean(tf.square(real_recon2)))\n",
    "                    loss3 = -tf.reduce_mean(tf.math.log(self.w3+1e-6) * pg_advantage)\n",
    "                            \n",
    "                    # Add extra losses created during this forward pass:\n",
    "                    #loss_value += sum(model.losses)\n",
    "\n",
    "                grads_ae1 = ae1_tape.gradient(loss1, self.ae_model1.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads_ae1, self.ae_model1.trainable_weights))\n",
    "                grads_ae2 = ae2_tape.gradient(loss2, self.ae_model2.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads_ae2, self.ae_model2.trainable_weights))\n",
    "                grads_ae3 = pg_tape.gradient(loss3, self.ae_model2.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads_ae3, self.ae_model2.trainable_weights))\n",
    "                \n",
    "                loss1_list.append(loss1)\n",
    "                loss2_list.append(loss2)\n",
    "                loss3_list.append(loss3)\n",
    "                \n",
    "            result = self.evaluate(val_loader, n)\n",
    "            self.epoch_end(n, result)\n",
    "            self.history.append(result)\n",
    "                \n",
    "            #print(\"Epoch [{}], train_loss1: {:.4f}, train_loss2: {:.4f}, train_loss3: {:.4f}\".format(n, np.mean(loss1_list), np.mean(loss2_list), np.mean(loss3_list)))\n",
    "            \n",
    "    def validation_step(self, batch, n):\n",
    "        z = self.encoder(batch)\n",
    "        w1 = self.decoder1(z)\n",
    "        w2 = self.decoder2(z)\n",
    "        w3 = self.decoder2(self.encoder(w1))\n",
    "        \n",
    "        real_recon1 = batch-w1\n",
    "        real_recon2 = batch-w2\n",
    "        fake_recon = batch-w3\n",
    "                \n",
    "        loss1 = 1/n*tf.reduce_mean(tf.square(batch-w1)) + (1-1/n)*tf.reduce_mean(tf.square(batch-w3))\n",
    "        loss2 = 1/n*tf.reduce_mean(tf.square(batch-w2)) + (1-1/n)*tf.reduce_mean(tf.square(batch-w3))\n",
    "        \n",
    "        pg_advantage = tf.reduce_mean(tf.square(fake_recon))-tf.reduce_mean(tf.square(real_recon2))\n",
    "        loss3 = -tf.reduce_mean(tf.math.log(w3+1e-6) * pg_advantage)\n",
    "        \n",
    "        return {'val_loss1': loss1, 'val_loss2': loss2, 'val_loss3': loss3}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses1 = [x['val_loss1'] for x in outputs]\n",
    "        epoch_loss1 = tf.reduce_mean(batch_losses1)\n",
    "        batch_losses2 = [x['val_loss2'] for x in outputs]\n",
    "        epoch_loss2 = tf.reduce_mean(batch_losses2)\n",
    "        batch_losses3 = [x['val_loss3'] for x in outputs]\n",
    "        epoch_loss3 = tf.reduce_mean(batch_losses3)\n",
    "        return {'val_loss1': epoch_loss1.numpy(), 'val_loss2': epoch_loss2.numpy(), 'val_loss3': epoch_loss3.numpy()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss1: {:.4f}, val_loss2: {:.4f}, val_loss2: {:.4f}\".format(epoch, result['val_loss1'], result['val_loss2'], result['val_loss3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Encoder.call of <__main__.Encoder object at 0x0000017FF32FA348>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Encoder.call of <__main__.Encoder object at 0x0000017FF32FA348>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017FF32FDD88>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017FF32FDD88>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017FF330E548>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Decoder.call of <__main__.Decoder object at 0x0000017FF330E548>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "usad_agm = UsadModel_AGM(w_size,z_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], val_loss1: 0.2053, val_loss2: 0.2092, val_loss2: -0.0035\n",
      "Epoch [2], val_loss1: 0.1554, val_loss2: 0.1571, val_loss2: -0.0510\n",
      "Epoch [3], val_loss1: 0.0843, val_loss2: 0.0809, val_loss2: -0.0926\n",
      "Epoch [4], val_loss1: 0.0485, val_loss2: 0.0497, val_loss2: -0.0473\n",
      "Epoch [5], val_loss1: 0.0379, val_loss2: 0.0418, val_loss2: -0.0091\n",
      "Epoch [6], val_loss1: 0.0291, val_loss2: 0.0329, val_loss2: -0.0022\n",
      "Epoch [7], val_loss1: 0.0147, val_loss2: 0.0163, val_loss2: -0.0104\n",
      "Epoch [8], val_loss1: 0.0079, val_loss2: 0.0084, val_loss2: -0.0125\n",
      "Epoch [9], val_loss1: 0.0058, val_loss2: 0.0058, val_loss2: -0.0169\n",
      "Epoch [10], val_loss1: 0.0055, val_loss2: 0.0053, val_loss2: -0.0189\n",
      "Epoch [11], val_loss1: 0.0055, val_loss2: 0.0053, val_loss2: -0.0203\n",
      "Epoch [12], val_loss1: 0.0054, val_loss2: 0.0052, val_loss2: -0.0234\n",
      "Epoch [13], val_loss1: 0.0054, val_loss2: 0.0050, val_loss2: -0.0312\n",
      "Epoch [14], val_loss1: 0.0053, val_loss2: 0.0048, val_loss2: -0.0456\n",
      "Epoch [15], val_loss1: 0.0055, val_loss2: 0.0049, val_loss2: -0.0617\n",
      "Epoch [16], val_loss1: 0.0061, val_loss2: 0.0056, val_loss2: -0.0669\n",
      "Epoch [17], val_loss1: 0.0073, val_loss2: 0.0069, val_loss2: -0.0740\n",
      "Epoch [18], val_loss1: 0.0082, val_loss2: 0.0079, val_loss2: -0.0733\n",
      "Epoch [19], val_loss1: 0.0089, val_loss2: 0.0087, val_loss2: -0.0726\n",
      "Epoch [20], val_loss1: 0.0096, val_loss2: 0.0094, val_loss2: -0.0752\n",
      "Epoch [21], val_loss1: 0.0106, val_loss2: 0.0105, val_loss2: -0.0763\n",
      "Epoch [22], val_loss1: 0.0116, val_loss2: 0.0115, val_loss2: -0.0793\n",
      "Epoch [23], val_loss1: 0.0123, val_loss2: 0.0122, val_loss2: -0.0823\n",
      "Epoch [24], val_loss1: 0.0122, val_loss2: 0.0122, val_loss2: -0.0779\n",
      "Epoch [25], val_loss1: 0.0117, val_loss2: 0.0116, val_loss2: -0.0677\n",
      "Epoch [26], val_loss1: 0.0111, val_loss2: 0.0110, val_loss2: -0.0569\n",
      "Epoch [27], val_loss1: 0.0104, val_loss2: 0.0104, val_loss2: -0.0479\n",
      "Epoch [28], val_loss1: 0.0099, val_loss2: 0.0098, val_loss2: -0.0412\n",
      "Epoch [29], val_loss1: 0.0094, val_loss2: 0.0093, val_loss2: -0.0359\n",
      "Epoch [30], val_loss1: 0.0090, val_loss2: 0.0090, val_loss2: -0.0317\n",
      "Epoch [31], val_loss1: 0.0087, val_loss2: 0.0086, val_loss2: -0.0283\n",
      "Epoch [32], val_loss1: 0.0084, val_loss2: 0.0083, val_loss2: -0.0256\n",
      "Epoch [33], val_loss1: 0.0082, val_loss2: 0.0081, val_loss2: -0.0235\n",
      "Epoch [34], val_loss1: 0.0080, val_loss2: 0.0079, val_loss2: -0.0217\n",
      "Epoch [35], val_loss1: 0.0078, val_loss2: 0.0077, val_loss2: -0.0201\n",
      "Epoch [36], val_loss1: 0.0076, val_loss2: 0.0075, val_loss2: -0.0187\n",
      "Epoch [37], val_loss1: 0.0074, val_loss2: 0.0073, val_loss2: -0.0178\n",
      "Epoch [38], val_loss1: 0.0073, val_loss2: 0.0072, val_loss2: -0.0166\n",
      "Epoch [39], val_loss1: 0.0071, val_loss2: 0.0071, val_loss2: -0.0160\n",
      "Epoch [40], val_loss1: 0.0070, val_loss2: 0.0069, val_loss2: -0.0148\n",
      "Epoch [41], val_loss1: 0.0068, val_loss2: 0.0068, val_loss2: -0.0147\n",
      "Epoch [42], val_loss1: 0.0067, val_loss2: 0.0067, val_loss2: -0.0136\n",
      "Epoch [43], val_loss1: 0.0067, val_loss2: 0.0066, val_loss2: -0.0133\n",
      "Epoch [44], val_loss1: 0.0066, val_loss2: 0.0065, val_loss2: -0.0128\n",
      "Epoch [45], val_loss1: 0.0065, val_loss2: 0.0064, val_loss2: -0.0123\n",
      "Epoch [46], val_loss1: 0.0064, val_loss2: 0.0063, val_loss2: -0.0119\n",
      "Epoch [47], val_loss1: 0.0063, val_loss2: 0.0063, val_loss2: -0.0115\n",
      "Epoch [48], val_loss1: 0.0062, val_loss2: 0.0062, val_loss2: -0.0112\n",
      "Epoch [49], val_loss1: 0.0062, val_loss2: 0.0061, val_loss2: -0.0110\n",
      "Epoch [50], val_loss1: 0.0061, val_loss2: 0.0061, val_loss2: -0.0108\n",
      "Epoch [51], val_loss1: 0.0061, val_loss2: 0.0061, val_loss2: -0.0107\n",
      "Epoch [52], val_loss1: 0.0061, val_loss2: 0.0061, val_loss2: -0.0106\n",
      "Epoch [53], val_loss1: 0.0061, val_loss2: 0.0060, val_loss2: -0.0105\n",
      "Epoch [54], val_loss1: 0.0060, val_loss2: 0.0060, val_loss2: -0.0104\n",
      "Epoch [55], val_loss1: 0.0060, val_loss2: 0.0060, val_loss2: -0.0103\n",
      "Epoch [56], val_loss1: 0.0060, val_loss2: 0.0060, val_loss2: -0.0103\n",
      "Epoch [57], val_loss1: 0.0060, val_loss2: 0.0060, val_loss2: -0.0102\n",
      "Epoch [58], val_loss1: 0.0060, val_loss2: 0.0060, val_loss2: -0.0102\n",
      "Epoch [59], val_loss1: 0.0060, val_loss2: 0.0059, val_loss2: -0.0101\n",
      "Epoch [60], val_loss1: 0.0060, val_loss2: 0.0059, val_loss2: -0.0100\n",
      "Epoch [61], val_loss1: 0.0059, val_loss2: 0.0059, val_loss2: -0.0100\n",
      "Epoch [62], val_loss1: 0.0059, val_loss2: 0.0059, val_loss2: -0.0099\n",
      "Epoch [63], val_loss1: 0.0059, val_loss2: 0.0059, val_loss2: -0.0098\n",
      "Epoch [64], val_loss1: 0.0059, val_loss2: 0.0058, val_loss2: -0.0098\n",
      "Epoch [65], val_loss1: 0.0058, val_loss2: 0.0058, val_loss2: -0.0097\n",
      "Epoch [66], val_loss1: 0.0058, val_loss2: 0.0058, val_loss2: -0.0097\n",
      "Epoch [67], val_loss1: 0.0058, val_loss2: 0.0058, val_loss2: -0.0096\n",
      "Epoch [68], val_loss1: 0.0058, val_loss2: 0.0057, val_loss2: -0.0095\n",
      "Epoch [69], val_loss1: 0.0057, val_loss2: 0.0057, val_loss2: -0.0094\n",
      "Epoch [70], val_loss1: 0.0057, val_loss2: 0.0057, val_loss2: -0.0093\n",
      "Epoch [71], val_loss1: 0.0056, val_loss2: 0.0056, val_loss2: -0.0092\n",
      "Epoch [72], val_loss1: 0.0056, val_loss2: 0.0056, val_loss2: -0.0090\n",
      "Epoch [73], val_loss1: 0.0056, val_loss2: 0.0055, val_loss2: -0.0089\n",
      "Epoch [74], val_loss1: 0.0055, val_loss2: 0.0055, val_loss2: -0.0087\n",
      "Epoch [75], val_loss1: 0.0054, val_loss2: 0.0054, val_loss2: -0.0085\n",
      "Epoch [76], val_loss1: 0.0054, val_loss2: 0.0054, val_loss2: -0.0083\n",
      "Epoch [77], val_loss1: 0.0053, val_loss2: 0.0053, val_loss2: -0.0081\n",
      "Epoch [78], val_loss1: 0.0052, val_loss2: 0.0052, val_loss2: -0.0077\n",
      "Epoch [79], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0069\n",
      "Epoch [80], val_loss1: 0.0050, val_loss2: 0.0050, val_loss2: -0.0055\n",
      "Epoch [81], val_loss1: 0.0053, val_loss2: 0.0053, val_loss2: -0.0047\n",
      "Epoch [82], val_loss1: 0.0054, val_loss2: 0.0054, val_loss2: -0.0045\n",
      "Epoch [83], val_loss1: 0.0054, val_loss2: 0.0054, val_loss2: -0.0043\n",
      "Epoch [84], val_loss1: 0.0055, val_loss2: 0.0055, val_loss2: -0.0042\n",
      "Epoch [85], val_loss1: 0.0056, val_loss2: 0.0056, val_loss2: -0.0040\n",
      "Epoch [86], val_loss1: 0.0056, val_loss2: 0.0056, val_loss2: -0.0039\n",
      "Epoch [87], val_loss1: 0.0056, val_loss2: 0.0056, val_loss2: -0.0037\n",
      "Epoch [88], val_loss1: 0.0057, val_loss2: 0.0057, val_loss2: -0.0036\n",
      "Epoch [89], val_loss1: 0.0057, val_loss2: 0.0057, val_loss2: -0.0035\n",
      "Epoch [90], val_loss1: 0.0057, val_loss2: 0.0057, val_loss2: -0.0034\n",
      "Epoch [91], val_loss1: 0.0057, val_loss2: 0.0057, val_loss2: -0.0034\n",
      "Epoch [92], val_loss1: 0.0058, val_loss2: 0.0058, val_loss2: -0.0033\n",
      "Epoch [93], val_loss1: 0.0058, val_loss2: 0.0058, val_loss2: -0.0032\n",
      "Epoch [94], val_loss1: 0.0058, val_loss2: 0.0058, val_loss2: -0.0032\n",
      "Epoch [95], val_loss1: 0.0058, val_loss2: 0.0058, val_loss2: -0.0031\n",
      "Epoch [96], val_loss1: 0.0058, val_loss2: 0.0058, val_loss2: -0.0031\n",
      "Epoch [97], val_loss1: 0.0058, val_loss2: 0.0058, val_loss2: -0.0030\n",
      "Epoch [98], val_loss1: 0.0059, val_loss2: 0.0059, val_loss2: -0.0030\n",
      "Epoch [99], val_loss1: 0.0059, val_loss2: 0.0059, val_loss2: -0.0030\n",
      "Epoch [100], val_loss1: 0.0059, val_loss2: 0.0059, val_loss2: -0.0029\n"
     ]
    }
   ],
   "source": [
    "usad_agm.training(train_loader, test_loader, N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymhjbmvR_DgJ"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model_usad.testing(whole_loader)\n",
    "a = np.concatenate([np.stack(a[:-1]).flatten(), a[-1].flatten()])\n",
    "b = model_usad.testing(train_loader)\n",
    "b = np.concatenate([np.stack(b[:-1]).flatten(), b[-1].flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot([x for x in range(a.shape[0])], a)\n",
    "plt.axhline(y=b.mean() + 5 * b.std(), color='r', linewidth=1)\n",
    "plt.title('Anomaly Detection')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Anomaly Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003685270348796621"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mean() + 5 * b.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1540"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.where(a < b.mean() + 5 * b.std())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ = a[:1541]\n",
    "np.where(a_ > b.mean() + 5 * b.std())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model_usad.testing(whole_loader)\n",
    "a = np.concatenate([np.stack(a[:-1]).flatten(), a[-1].flatten()])\n",
    "b = model_usad.testing(train_loader)\n",
    "b = np.concatenate([np.stack(b[:-1]).flatten(), b[-1].flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot([x for x in range(a.shape[0])], a)\n",
    "plt.axhline(y=b.mean() + 5 * b.std(), color='r', linewidth=1)\n",
    "plt.title('Anomaly Detection')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Anomaly Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00041529581358190626"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mean() + 5 * b.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1541"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.where(a < b.mean() + 5 * b.std())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ = a[:1541]\n",
    "np.where(a_ > b.mean() + 5 * b.std())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "USAD_test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
