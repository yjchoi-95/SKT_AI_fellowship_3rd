{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlprimitives.custom.timeseries_preprocessing import time_segments_aggregate\n",
    "from mlprimitives.custom.timeseries_preprocessing import rolling_window_sequences\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from notebooks.tulog.model import hyperparameters\n",
    "from orion.primitives.tadgan import TadGAN\n",
    "from orion.data import load_signal, load_anomalies\n",
    "from orion import Orion\n",
    "from notebooks.tulog.utils import plot, plot_ts, plot_rws, plot_error, unroll_ts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2803, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"C:\\\\Users\\\\PC\\\\OneDrive\\\\문서\\\\GitHub\\\\datasets\\\\\"\n",
    "\n",
    "#Read data\n",
    "data = pd.read_csv(data_path + \"Bearing1_1_top5_result.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nomalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "x = data.values\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "scaled_data = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2803, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = scaled_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size=100\n",
    "windows_normal=scaled_data.values[np.arange(window_size)[None, :] + np.arange(scaled_data.shape[0]-window_size)[:, None]]\n",
    "windows_normal = np.expand_dims(windows_normal,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_normal_train = windows_normal[:400]\n",
    "windows_normal_test = windows_normal[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 100, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows_normal_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2303, 100, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows_normal_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch: 1/100, [Dx loss: [ 2.4001782  -0.0377054   0.04182352  0.23960601]] [Dz loss: [ 0.4529787  -0.9207913   0.49542984  0.087834  ]] [G loss: [-0.452523   -0.03832104 -0.45670325  0.00425013]]\n",
      "Epoch: 2/100, [Dx loss: [ 0.12405848  0.18915579 -0.22797376  0.01628765]] [Dz loss: [-2.2815044  -2.3975399  -1.1813706   0.12974064]] [G loss: [3.3663974  0.33775377 2.7824206  0.0246223 ]]\n",
      "Epoch: 3/100, [Dx loss: [ 0.28016943  0.7526541  -0.52839875  0.00559141]] [Dz loss: [-2.2626667  -2.111272   -2.4187071   0.22673127]] [G loss: [3.1699412  0.48916006 2.5510538  0.01297276]]\n",
      "Epoch: 4/100, [Dx loss: [-0.41378355 -1.871019    1.3598007   0.00974345]] [Dz loss: [-0.6308606 -2.2960055  1.4066397  0.0258505]] [G loss: [-2.5742316  -1.3963258  -1.2970697   0.01191639]]\n",
      "Epoch: 5/100, [Dx loss: [ 0.35460815 -0.9531062   1.1601387   0.01475757]] [Dz loss: [-2.6373913  -3.9523795  -0.40473077  0.17197192]] [G loss: [ 1.1419746  -0.34878573  1.0654371   0.04253229]]\n",
      "Epoch: 6/100, [Dx loss: [-0.7745837   2.1937726  -3.0770144   0.01086584]] [Dz loss: [-5.815262   -4.141751   -4.10411     0.24305971]] [G loss: [7.6248465  3.0983906  4.4198184  0.01066375]]\n",
      "Epoch: 7/100, [Dx loss: [-0.0102375  -2.1984494   2.0491157   0.01390965]] [Dz loss: [-3.480801   -2.9697301  -1.2734631   0.07623922]] [G loss: [-1.1937104  -2.959343    1.4615204   0.03041121]]\n",
      "Epoch: 8/100, [Dx loss: [-6.8679607e-01 -8.7919292e+00  8.0276871e+00  7.7445465e-03]] [Dz loss: [-1.6343471  -3.112633    1.0090071   0.04692788]] [G loss: [-8.364651   -7.8601365  -0.6969193   0.01924053]]\n",
      "Epoch: 9/100, [Dx loss: [ 0.67232525 -6.1862416   6.773771    0.00847957]] [Dz loss: [-3.7162144 -3.9816022 -1.1274987  0.1392886]] [G loss: [-3.0273871  -5.1985626   1.9305273   0.02406479]]\n",
      "Epoch: 10/100, [Dx loss: [-1.6973578   3.1602566  -5.0512886   0.01936743]] [Dz loss: [-4.67945    -3.764085   -2.100577    0.11852118]] [G loss: [7.5895777  4.782232   2.5266879  0.02806576]]\n",
      "Epoch: 11/100, [Dx loss: [ 1.5542363e-01  6.6932044e+00 -6.5744863e+00  3.6705686e-03]] [Dz loss: [-2.587039   -3.619512    0.44588926  0.05865836]] [G loss: [ 7.3854060e+00  7.3519406e+00 -9.7033959e-03  4.3168538e-03]]\n",
      "Epoch: 12/100, [Dx loss: [ 2.5379896e-01  1.6931587e+01 -1.6843687e+01  1.6589727e-02]] [Dz loss: [-3.7460754  -3.7880023  -0.8384168   0.08803431]] [G loss: [1.8804838e+01 1.7078297e+01 1.5976356e+00 1.2890582e-02]]\n",
      "Epoch: 13/100, [Dx loss: [-0.93706936  2.4306948  -3.5096943   0.01419293]] [Dz loss: [-4.285134   -2.9269123  -2.3891585   0.10309374]] [G loss: [5.5487714  2.550116   2.9280133  0.00706419]]\n",
      "Epoch: 14/100, [Dx loss: [-0.1318365   0.62131554 -0.78737694  0.00342249]] [Dz loss: [-1.8717083  -2.5156357   0.20319504  0.04407326]] [G loss: [1.3170316  0.9978687  0.22956915 0.00895938]]\n",
      "Epoch: 15/100, [Dx loss: [ 0.26556587  2.8852656  -2.6795566   0.00598568]] [Dz loss: [-2.58818    -3.2512295   0.18651934  0.04765306]] [G loss: [4.6519523  3.9334471  0.5932406  0.01252647]]\n",
      "Epoch: 16/100, [Dx loss: [-7.4170184e-01  1.0410255e+01 -1.1210070e+01  5.8112619e-03]] [Dz loss: [-3.959046   -2.2905731  -2.600709    0.09322363]] [G loss: [14.208991   10.654937    3.3498423   0.02042125]]\n",
      "Epoch: 17/100, [Dx loss: [ 1.4008801e-01  6.3322730e+00 -6.2266150e+00  3.4428616e-03]] [Dz loss: [-1.7900977  -0.729059   -1.452904    0.03918652]] [G loss: [8.2996836e+00 6.1667123e+00 2.0945818e+00 3.8388867e-03]]\n",
      "Epoch: 18/100, [Dx loss: [ 0.79144305  5.4635215  -4.752129    0.00800516]] [Dz loss: [-0.7759861  -0.6746971  -0.37106562  0.02697767]] [G loss: [5.5942683  4.5381923  0.9759299  0.00801464]]\n",
      "Epoch: 19/100, [Dx loss: [-1.0722123   7.181426   -8.439472    0.01858336]] [Dz loss: [ 2.445408   -0.1642493   2.2333148   0.03763431]] [G loss: [10.327977    9.0679655   0.7008508   0.05591615]]\n",
      "Epoch: 20/100, [Dx loss: [-4.3377891e-01  1.0279448e+01 -1.0760729e+01  4.7502201e-03]] [Dz loss: [ -9.608241     4.6874065  -17.72926      0.34336182]] [G loss: [3.5294308e+01 1.0911996e+01 2.4230837e+01 1.5147718e-02]]\n",
      "Epoch: 21/100, [Dx loss: [ 3.4639228e-02  1.1207404e+01 -1.1205754e+01  3.2989073e-03]] [Dz loss: [-22.596285    7.0896454 -40.223007    1.0537078]] [G loss: [6.0495918e+01 1.1327477e+01 4.9120655e+01 4.7783521e-03]]\n",
      "Epoch: 22/100, [Dx loss: [ 3.7396845e-01  1.4803704e+01 -1.4467569e+01  3.7834283e-03]] [Dz loss: [-1.6373489  4.622116  -7.2142515  0.0954788]] [G loss: [2.2397619e+01 1.5051135e+01 7.3069572e+00 3.9527114e-03]]\n",
      "Epoch: 23/100, [Dx loss: [ 3.0782810e-01  2.7245790e+01 -2.7127495e+01  1.8953687e-02]] [Dz loss: [ 1.2830577   3.1244123  -2.3528233   0.05114689]] [G loss: [3.0246311e+01 2.7708389e+01 2.3331349e+00 2.0478768e-02]]\n",
      "Epoch: 24/100, [Dx loss: [-6.9067156e-01  1.3194482e+01 -1.3984360e+01  9.9206036e-03]] [Dz loss: [ 1.5664802   2.5762875  -1.6160749   0.06062675]] [G loss: [14.711665   12.77907     1.7310047   0.02015924]]\n",
      "Epoch: 25/100, [Dx loss: [-2.9634264e-01  7.9655280e+00 -8.3009748e+00  3.9104712e-03]] [Dz loss: [ 1.1836416   2.3678584  -1.6287258   0.04445081]] [G loss: [1.0170702e+01 8.3207731e+00 1.8025182e+00 4.7410228e-03]]\n",
      "Epoch: 26/100, [Dx loss: [ 3.4110215e-02  9.5423784e+00 -9.5428286e+00  3.4560624e-03]] [Dz loss: [ 1.0273495   2.0854568  -1.4449626   0.03868549]] [G loss: [1.1272744e+01 9.6546078e+00 1.5911009e+00 2.7034900e-03]]\n",
      "Epoch: 27/100, [Dx loss: [ 3.2579863e-01  1.0626910e+01 -1.0335362e+01  3.4250321e-03]] [Dz loss: [ 1.1327256   1.7441896  -0.9139184   0.03024544]] [G loss: [1.1618086e+01 1.0561584e+01 1.0088011e+00 4.7699758e-03]]\n",
      "Epoch: 28/100, [Dx loss: [ 4.8645341e-01  1.3293648e+01 -1.2854073e+01  4.6877982e-03]] [Dz loss: [ 2.3306363   1.4657396  -0.03302615  0.08979221]] [G loss: [1.3620435e+01 1.3283945e+01 2.5310451e-01 8.3384980e-03]]\n",
      "Epoch: 29/100, [Dx loss: [-0.44870788  7.825832   -8.365696    0.00911548]] [Dz loss: [-0.31364253  1.5885627  -2.6638813   0.07616767]] [G loss: [10.763597    7.268631    3.3287828   0.01661837]]\n",
      "Epoch: 30/100, [Dx loss: [-0.641861    2.124314   -2.8196716   0.00534962]] [Dz loss: [ 2.0711377   1.621566   -0.44238752  0.08919591]] [G loss: [3.2927513  2.6396775  0.5524004  0.01006735]]\n",
      "Epoch: 31/100, [Dx loss: [-0.41224882 -0.49237776  0.04699843  0.00331305]] [Dz loss: [ 0.39546302  1.7593354  -1.8646103   0.0500738 ]] [G loss: [ 2.3401399  -0.15931289  2.4461825   0.00532703]]\n",
      "Epoch: 32/100, [Dx loss: [-0.11597178  0.19656044 -0.34348288  0.00309507]] [Dz loss: [ 0.01916103  2.4475498  -2.917473    0.04890843]] [G loss: [3.6661363e+00 3.1049830e-01 3.3203971e+00 3.5241174e-03]]\n",
      "Epoch: 33/100, [Dx loss: [ 0.04783338 -2.7862      2.8043838   0.00296491]] [Dz loss: [ 1.8470529   2.4588494  -1.3736267   0.07618304]] [G loss: [-1.4176952  -3.025357    1.5688356   0.00388263]]\n",
      "Epoch: 34/100, [Dx loss: [ 2.2601223e-01 -4.6704345e+00  4.8612885e+00  3.5158384e-03]] [Dz loss: [ 0.11138753  2.2274852  -2.515752    0.03996541]] [G loss: [-2.4688413e+00 -5.2850227e+00  2.7805431e+00  3.5638106e-03]]\n",
      "Epoch: 35/100, [Dx loss: [ 1.3133042e-01 -5.7775474e+00  5.8573270e+00  5.1551126e-03]] [Dz loss: [ 0.7825507   1.6530796  -1.2746342   0.04041053]] [G loss: [-3.8775256  -5.386918    1.4516871   0.00577049]]\n",
      "Epoch: 36/100, [Dx loss: [-0.4210571  -1.9276971   1.4518716   0.00547684]] [Dz loss: [ 0.7050264   1.2908008  -1.0311863   0.04454121]] [G loss: [ 0.05932212 -1.2594388   1.2493131   0.00694478]]\n",
      "Epoch: 37/100, [Dx loss: [-0.3112371   0.37550816 -0.73026437  0.00435191]] [Dz loss: [-0.1623129   1.1760744  -1.7457901   0.04074027]] [G loss: [3.1352735  0.91769665 2.1652799  0.0052297 ]]\n",
      "Epoch: 38/100, [Dx loss: [-0.13829021  0.86781377 -1.039756    0.00336517]] [Dz loss: [-0.62421197  1.2796762  -2.2802336   0.03763455]] [G loss: [3.5804713  0.8109545  2.7322612  0.00372556]]\n",
      "Epoch: 39/100, [Dx loss: [-0.0309987  -0.14208034  0.07884017  0.00322414]] [Dz loss: [-0.39772758  1.3721529  -2.151172    0.03812915]] [G loss: [2.5738204e+00 5.8069974e-03 2.5423872e+00 2.5625862e-03]]\n",
      "Epoch: 40/100, [Dx loss: [ 0.00649969  0.7298746  -0.77852     0.0055145 ]] [Dz loss: [ 0.7003879   1.429842   -1.1240246   0.03945706]] [G loss: [2.193422   0.7198619  1.443616   0.00299441]]\n",
      "Epoch: 41/100, [Dx loss: [-0.13654001 -3.3170655   3.0950677   0.00854585]] [Dz loss: [ 0.7169742   1.6178907  -1.4795691   0.05786524]] [G loss: [-1.5500134e+00 -3.5292852e+00  1.9473013e+00  3.1970444e-03]]\n",
      "Epoch: 42/100, [Dx loss: [-0.17104603 -3.9415188   3.7039747   0.00664971]] [Dz loss: [-0.60286844  1.9310765  -3.015806    0.04818609]] [G loss: [ 3.8681883e-01 -3.1934431e+00  3.5460770e+00  3.4185047e-03]]\n",
      "Epoch: 43/100, [Dx loss: [-0.19809303 -4.952503    4.6984773   0.00559327]] [Dz loss: [ 0.23738992  1.9416275  -2.2183125   0.05140749]] [G loss: [-2.3923950e+00 -4.9385648e+00  2.5096881e+00  3.6481698e-03]]\n",
      "Epoch: 44/100, [Dx loss: [-7.1885988e-02 -4.5480843e+00  4.4405150e+00  3.5683496e-03]] [Dz loss: [ 1.653008    2.0612276  -1.3882288   0.09800091]] [G loss: [-1.436855   -4.0589337   2.5634658   0.00586128]]\n",
      "Epoch: 45/100, [Dx loss: [ 0.06854581 -3.4148169   3.4487133   0.00346488]] [Dz loss: [-2.1787028   3.5398877  -6.514654    0.07960641]] [G loss: [ 4.9412813e+00 -3.6477044e+00  8.5319586e+00  5.7027303e-03]]\n",
      "Epoch: 46/100, [Dx loss: [ 2.0590056e-01 -7.2792120e+00  7.4479980e+00  3.7114287e-03]] [Dz loss: [-10.854217     5.171073   -18.453253     0.24279605]] [G loss: [ 1.5126015e+01 -7.6386805e+00  2.2710190e+01  5.4506636e-03]]\n",
      "Epoch: 47/100, [Dx loss: [ 1.13109626e-01 -7.14609289e+00  7.21357155e+00  4.56318213e-03]] [Dz loss: [ -8.3305645   4.9285564 -17.200365    0.3941242]] [G loss: [ 1.1646325e+01 -6.8292618e+00  1.8420471e+01  5.5116154e-03]]\n",
      "Epoch: 48/100, [Dx loss: [-0.33565378 -0.7452112   0.36200845  0.0047549 ]] [Dz loss: [-2.1790795   3.9891946  -6.7099514   0.05416772]] [G loss: [ 7.0284829e+00 -1.9402786e-01  7.1672316e+00  5.5278302e-03]]\n",
      "Epoch: 49/100, [Dx loss: [-0.25660992 -3.8601816   3.5649495   0.00386222]] [Dz loss: [-1.7028747   3.859949   -6.008827    0.04460035]] [G loss: [ 2.8501890e+00 -3.8936462e+00  6.7038507e+00  3.9984561e-03]]\n",
      "Epoch: 50/100, [Dx loss: [-1.2507334e-01 -5.3942080e+00  5.2363901e+00  3.2743996e-03]] [Dz loss: [ 1.0048233   3.6083164  -2.9510334   0.03475397]] [G loss: [-2.0193777e+00 -5.1184173e+00  3.0645688e+00  3.4471466e-03]]\n",
      "Epoch: 51/100, [Dx loss: [-0.11993028 -2.2616289   2.0880268   0.0053672 ]] [Dz loss: [ 1.1177402   2.8933675  -2.0104825   0.02348558]] [G loss: [ 0.30066103 -1.7572128   2.0268285   0.00310453]]\n",
      "Epoch: 52/100, [Dx loss: [-0.16862142 -0.67041737  0.43506873  0.00667272]] [Dz loss: [ 1.8142016   2.5784776  -1.0982251   0.03339496]] [G loss: [ 0.7243046  -0.39159873  1.0949637   0.00209397]]\n",
      "Epoch: 53/100, [Dx loss: [-0.06965605  0.24361466 -0.37434927  0.00610786]] [Dz loss: [ 2.5436602   2.2868836  -0.42949897  0.06862757]] [G loss: [1.0021088 0.5373712 0.4314846 0.0033253]]\n",
      "Epoch: 54/100, [Dx loss: [-0.17319274  1.1057255  -1.3372775   0.00583592]] [Dz loss: [3.0667205  1.7961376  0.17966045 0.10909221]] [G loss: [ 1.1792078   1.3376148  -0.19746324  0.00390562]]\n",
      "Epoch: 55/100, [Dx loss: [-0.0717005   0.4342582  -0.5620178   0.00560592]] [Dz loss: [2.398285   0.9454451  0.9199879  0.05328518]] [G loss: [-0.02764891  0.83641016 -0.89890844  0.00348493]]\n",
      "Epoch: 56/100, [Dx loss: [-0.02001499  3.2454984  -3.3328943   0.00673812]] [Dz loss: [ 1.3868872  -0.04828502  1.0397407   0.03954314]] [G loss: [ 2.656556    3.4384303  -0.820429    0.00385549]]\n",
      "Epoch: 57/100, [Dx loss: [ 0.15250485  2.9179907  -2.8395593   0.00740733]] [Dz loss: [-0.2311364  -1.1093478  -0.10490956  0.09831209]] [G loss: [3.1522677  2.7664666  0.31319216 0.00726089]]\n",
      "Epoch: 58/100, [Dx loss: [ 0.06596399  3.7245853  -3.723359    0.00647383]] [Dz loss: [-2.5617878  -1.8139279  -1.765906    0.10180464]] [G loss: [6.0717654  3.8959782  2.0486326  0.01271543]]\n",
      "Epoch: 59/100, [Dx loss: [-0.05299158  7.241509   -7.3715653   0.00770647]] [Dz loss: [-4.3240156  -2.1682396  -2.9722202   0.08164442]] [G loss: [1.1011368e+01 7.6417131e+00 3.2624462e+00 1.0720787e-02]]\n",
      "Epoch: 60/100, [Dx loss: [-1.5466598e-01  1.0647332e+01 -1.0873882e+01  7.1884710e-03]] [Dz loss: [-3.598032   -2.471381   -1.7071972   0.05805464]] [G loss: [1.3004436e+01 1.1123426e+01 1.8273871e+00 5.3623626e-03]]\n",
      "Epoch: 61/100, [Dx loss: [-9.54789072e-02  1.27745075e+01 -1.29288912e+01  5.89040108e-03]] [Dz loss: [-2.5120895  -2.9456663   0.02404894  0.04095281]] [G loss: [1.2703544e+01 1.2619097e+01 5.2099627e-02 3.2344512e-03]]\n",
      "Epoch: 62/100, [Dx loss: [-1.969705e-02  9.039720e+00 -9.108040e+00  4.862187e-03]] [Dz loss: [-1.619637   -3.4154937   1.4195398   0.03763171]] [G loss: [ 7.7020297e+00  9.0075579e+00 -1.3329761e+00  2.7446279e-03]]\n",
      "Epoch: 63/100, [Dx loss: [ 7.7918701e-02  7.1126685e+00 -7.0893946e+00  5.4644686e-03]] [Dz loss: [-1.313117   -3.8627129   2.2036948   0.03459012]] [G loss: [ 5.0889616e+00  7.0462995e+00 -1.9806713e+00  2.3332697e-03]]\n",
      "Epoch: 64/100, [Dx loss: [-8.3093204e-02  1.0405894e+01 -1.0571861e+01  8.2872324e-03]] [Dz loss: [-3.050628  -4.3383813  0.6039539  0.06838  ]] [G loss: [ 1.0436552e+01  1.0723563e+01 -3.1666943e-01  2.9657872e-03]]\n",
      "Epoch: 65/100, [Dx loss: [-1.9848671e-02  1.0318423e+01 -1.0415423e+01  7.7152275e-03]] [Dz loss: [-5.020948   -4.865034   -1.2920141   0.11361012]] [G loss: [1.1571642e+01 1.0089686e+01 1.4539691e+00 2.7987126e-03]]\n",
      "Epoch: 66/100, [Dx loss: [-2.4615616e-02  7.5160627e+00 -7.6043987e+00  6.3720881e-03]] [Dz loss: [-5.293698   -4.890341   -1.4365711   0.10332138]] [G loss: [9.4508257e+00 7.8201766e+00 1.5991659e+00 3.1481837e-03]]\n",
      "Epoch: 67/100, [Dx loss: [-1.00792825e-01  1.01436768e+01 -1.03120565e+01  6.75854133e-03]] [Dz loss: [-3.0842147 -4.459262   0.8403079  0.0534739]] [G loss: [ 9.6616087e+00  1.0463349e+01 -8.3312380e-01  3.1383301e-03]]\n",
      "Epoch: 68/100, [Dx loss: [-3.2752842e-02  1.0190621e+01 -1.0291338e+01  6.7963707e-03]] [Dz loss: [-1.7241693  -4.6665196   2.6343148   0.03080359]] [G loss: [ 7.6295557e+00  1.0149483e+01 -2.5522466e+00  3.2319964e-03]]\n",
      "Epoch: 69/100, [Dx loss: [-9.6199974e-02  1.0526728e+01 -1.0687357e+01  6.4429217e-03]] [Dz loss: [-2.438825   -5.2031655   2.2448108   0.05195297]] [G loss: [ 8.6858006e+00  1.0753364e+01 -2.0913463e+00  2.3782202e-03]]\n",
      "Epoch: 70/100, [Dx loss: [-5.2766614e-02  1.0273142e+01 -1.0392295e+01  6.6385292e-03]] [Dz loss: [-3.5648816  -5.5303497   1.3345282   0.06309394]] [G loss: [ 8.8609934e+00  1.0091489e+01 -1.2620080e+00  3.1512605e-03]]\n",
      "Epoch: 71/100, [Dx loss: [-1.2418275e-01  1.1404358e+01 -1.1595543e+01  6.7004086e-03]] [Dz loss: [-3.400261   -5.7145977   1.7989823   0.05153546]] [G loss: [ 1.0320752e+01  1.2043121e+01 -1.7477428e+00  2.5373534e-03]]\n",
      "Epoch: 72/100, [Dx loss: [-8.5267983e-02  1.6873665e+01 -1.7020180e+01  6.1248811e-03]] [Dz loss: [-2.8377082  -5.860862    2.50821     0.05149423]] [G loss: [ 1.4770488e+01  1.7195538e+01 -2.4576929e+00  3.2643697e-03]]\n",
      "Epoch: 73/100, [Dx loss: [-1.04122721e-01  1.54081545e+01 -1.55685701e+01  5.62953204e-03]] [Dz loss: [-2.9266977  -5.9432335   2.3562915   0.06602438]] [G loss: [ 1.2641143e+01  1.4851281e+01 -2.2404904e+00  3.0350627e-03]]\n",
      "Epoch: 74/100, [Dx loss: [-1.7169929e-01  1.3147630e+01 -1.3396995e+01  7.7666221e-03]] [Dz loss: [-3.320547   -5.651101    1.6860561   0.06444978]] [G loss: [ 1.1705932e+01  1.3242974e+01 -1.5688468e+00  3.1805804e-03]]\n",
      "Epoch: 75/100, [Dx loss: [-3.5402160e-02  9.2674675e+00 -9.3907309e+00  8.7861121e-03]] [Dz loss: [-3.0202756  -5.302086    1.7772431   0.05045668]] [G loss: [ 7.2436304e+00  8.9240570e+00 -1.7041320e+00  2.3705238e-03]]\n",
      "Epoch: 76/100, [Dx loss: [-0.03256181  8.195391   -8.319066    0.00911132]] [Dz loss: [-2.451938   -5.1433372   2.3138568   0.03775419]] [G loss: [ 6.4716458e+00  8.6549549e+00 -2.2097213e+00  2.6411377e-03]]\n",
      "Epoch: 77/100, [Dx loss: [-1.2625688e-01  1.4353530e+01 -1.4571825e+01  9.2040598e-03]] [Dz loss: [-2.8907263  -5.4099894   2.0040631   0.05151996]] [G loss: [ 1.1999448e+01  1.3815486e+01 -1.8478317e+00  3.1793914e-03]]\n",
      "Epoch: 78/100, [Dx loss: [-0.22180964  0.25444984 -0.54332024  0.00670607]] [Dz loss: [-3.8676353  -5.4876842   0.96270096  0.0657348 ]] [G loss: [-0.72038925  0.08611892 -0.8346543   0.0028146 ]]\n",
      "Epoch: 79/100, [Dx loss: [-0.2572949   2.7997084  -3.12261     0.00656069]] [Dz loss: [-3.3627422  -5.254135    1.4136691   0.04777227]] [G loss: [ 2.0339139e+00  3.3705127e+00 -1.3599900e+00  2.3391049e-03]]\n",
      "Epoch: 80/100, [Dx loss: [ 0.19059025 -2.1246188   2.2443423   0.00708664]] [Dz loss: [-2.0663738  -5.313382    2.9859624   0.02610466]] [G loss: [-4.9145646e+00 -1.9836590e+00 -2.9535193e+00  2.2613709e-03]]\n",
      "Epoch: 81/100, [Dx loss: [-0.01346891 -0.6031628   0.5315351   0.00581587]] [Dz loss: [-1.7253215  -6.06472     4.0543      0.02850998]] [G loss: [-4.1848974e+00 -2.4976775e-01 -3.9577155e+00  2.2585446e-03]]\n",
      "Epoch: 82/100, [Dx loss: [ 0.01574015  3.7118204  -3.74965     0.00535701]] [Dz loss: [-2.7756627 -6.7184787  3.3388162  0.0604   ]] [G loss: [ 4.3983215e-01  3.6144922e+00 -3.2002869e+00  2.5626679e-03]]\n",
      "Epoch: 83/100, [Dx loss: [ 1.4453380e-02  6.9054995e+00 -6.9530663e+00  6.2019522e-03]] [Dz loss: [-3.6428833  -6.4175806   2.0962238   0.06784731]] [G loss: [ 4.3186789e+00  6.2610126e+00 -1.9663645e+00  2.4030725e-03]]\n",
      "Epoch: 84/100, [Dx loss: [-0.26155168  2.1087277  -2.4296522   0.00593726]] [Dz loss: [-3.6327746  -6.021932    1.8278881   0.05612686]] [G loss: [ 7.8719968e-01  2.5219681e+00 -1.7567235e+00  2.1955334e-03]]\n",
      "Epoch: 85/100, [Dx loss: [ 0.00400618 -0.85824245  0.7889814   0.00732672]] [Dz loss: [-2.925554   -5.6966586   2.372191    0.03989143]] [G loss: [-3.9187448e+00 -1.5866140e+00 -2.3506329e+00  1.8502231e-03]]\n",
      "Epoch: 86/100, [Dx loss: [ 1.8564223e-01 -7.8279443e+00  7.9454675e+00  6.8119592e-03]] [Dz loss: [-2.310382   -5.6680703   3.0422578   0.03154308]] [G loss: [-1.0926308e+01 -7.9549599e+00 -2.9923725e+00  2.1023955e-03]]\n",
      "Epoch: 87/100, [Dx loss: [-1.4909567e-01 -8.0025196e+00  7.7958646e+00  5.7560406e-03]] [Dz loss: [-2.1846082  -5.9735355   3.4244976   0.03644299]] [G loss: [-1.0836179e+01 -7.4871602e+00 -3.3712430e+00  2.2226169e-03]]\n",
      "Epoch: 88/100, [Dx loss: [ 7.772060e-02 -5.794170e+00  5.819703e+00  5.218782e-03]] [Dz loss: [-2.6412349  -6.272097    3.178287    0.04525755]] [G loss: [-8.7950878e+00 -5.7007742e+00 -3.1172547e+00  2.2941174e-03]]\n",
      "Epoch: 89/100, [Dx loss: [-0.07692329 -3.3440707   3.1877682   0.00793794]] [Dz loss: [-3.0407507 -6.1634674  2.677011   0.0445706]] [G loss: [-6.1987181e+00 -3.6064246e+00 -2.6203697e+00  2.8076712e-03]]\n",
      "Epoch: 90/100, [Dx loss: [-0.21071221 -6.314118    6.0154753   0.00879294]] [Dz loss: [-3.012652   -6.039063    2.5810573   0.04453545]] [G loss: [-8.3253708e+00 -5.8005872e+00 -2.5557513e+00  3.0968343e-03]]\n",
      "Epoch: 91/100, [Dx loss: [ 4.8160008e-03 -6.0457435e+00  5.9813743e+00  6.9185812e-03]] [Dz loss: [-2.8445404  -5.974522    2.7004957   0.04294865]] [G loss: [-8.4749136e+00 -5.8039103e+00 -2.6988838e+00  2.7881416e-03]]\n",
      "Epoch: 92/100, [Dx loss: [-0.12056581 -0.9177028   0.73160625  0.00655306]] [Dz loss: [-2.8344133 -6.0625052  2.761611   0.0466481]] [G loss: [-2.6180303e+00  5.6462221e-02 -2.6935928e+00  1.9100227e-03]]\n",
      "Epoch: 93/100, [Dx loss: [ 3.5633513e-01  8.2385178e+00 -7.9576659e+00  7.5483560e-03]] [Dz loss: [-2.8387115  -5.9982624   2.6912122   0.04683388]] [G loss: [ 6.1876187e+00  8.8105326e+00 -2.6416631e+00  1.8749357e-03]]\n",
      "Epoch: 94/100, [Dx loss: [-1.4303546e-01  6.1085119e+00 -6.3055873e+00  5.4039410e-03]] [Dz loss: [-2.9190018  -5.981814    2.5728354   0.04899776]] [G loss: [ 3.9319415e+00  6.4679327e+00 -2.5583768e+00  2.2385777e-03]]\n",
      "Epoch: 95/100, [Dx loss: [-3.0128366e-01  8.1709805e+00 -8.5231848e+00  5.0921524e-03]] [Dz loss: [-2.9955695  -5.9429603   2.5110648   0.04363271]] [G loss: [ 6.1040010e+00  8.5478411e+00 -2.4580550e+00  1.4215721e-03]]\n",
      "Epoch: 96/100, [Dx loss: [ 1.18714780e-01  1.23174515e+01 -1.22930517e+01  9.43153445e-03]] [Dz loss: [-2.9334435 -5.910563   2.5419579  0.0435161]] [G loss: [ 1.1293309e+01  1.3750855e+01 -2.4785831e+00  2.1036586e-03]]\n",
      "Epoch: 97/100, [Dx loss: [ 1.2910746e-01  1.5201341e+01 -1.5145445e+01  7.3207719e-03]] [Dz loss: [-2.7961948 -5.92358    2.6936119  0.0433774]] [G loss: [ 1.2013236e+01  1.4651392e+01 -2.6596150e+00  2.1459218e-03]]\n",
      "Epoch: 98/100, [Dx loss: [-4.99597825e-02  1.32740450e+01 -1.33705845e+01  4.65792138e-03]] [Dz loss: [-2.7679787  -6.030634    2.7493687   0.05132868]] [G loss: [ 1.0238183e+01  1.2937661e+01 -2.7295365e+00  3.0059894e-03]]\n",
      "Epoch: 99/100, [Dx loss: [-2.7251133e-01  1.0113001e+01 -1.0428596e+01  4.3085990e-03]] [Dz loss: [-3.1209033  -6.0127606   2.3099086   0.05819481]] [G loss: [ 8.0450115e+00  1.0269980e+01 -2.2499874e+00  2.5018516e-03]]\n",
      "Epoch: 100/100, [Dx loss: [ 2.41595730e-02  1.02487278e+01 -1.02992525e+01  7.46858632e-03]] [Dz loss: [-3.4908972  -5.9257197   1.8903822   0.05444405]] [G loss: [ 7.2484078e+00  9.0589428e+00 -1.8307420e+00  2.0207039e-03]]\n"
     ]
    }
   ],
   "source": [
    "hyperparameters[\"epochs\"] = 100\n",
    "hyperparameters[\"shape\"] = (100, 1) # based on the window size\n",
    "hyperparameters[\"optimizer\"] = \"keras.optimizers.Adam\"\n",
    "hyperparameters[\"learning_rate\"] = 0.0005\n",
    "hyperparameters[\"latent_dim\"] = 20\n",
    "hyperparameters[\"batch_size\"] = 64\n",
    "\n",
    "tgan = TadGAN(**hyperparameters)\n",
    "tgan.fit(windows_normal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct\n",
    "X_hat, critic = tgan.predict(X)\n",
    "\n",
    "# visualize X_hat\n",
    "plot_rws(X_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the predicted windows\n",
    "y_hat = unroll_ts(X_hat)\n",
    "\n",
    "# plot the time series\n",
    "plot_ts([y, y_hat], labels=['original', 'reconstructed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair-wise error calculation\n",
    "error = np.zeros(shape=y.shape)\n",
    "length = y.shape[0]\n",
    "for i in range(length):\n",
    "    error[i] = abs(y_hat[i] - y[i])\n",
    "\n",
    "# visualize the error curve\n",
    "fig = plt.figure(figsize=(30, 3))\n",
    "plt.plot(error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orion.primitives.tadgan import score_anomalies\n",
    "\n",
    "error, true_index, true, pred = score_anomalies(X, X_hat, critic, X_index, rec_error_type=\"dtw\", comb=\"mult\")\n",
    "pred = np.array(pred).mean(axis=2)\n",
    "\n",
    "# visualize the error curve\n",
    "plot_error([[true, pred], error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold\n",
    "thresh = 10\n",
    "\n",
    "intervals = list()\n",
    "\n",
    "i = 0\n",
    "max_start = len(error)\n",
    "while i < max_start:\n",
    "    j = i\n",
    "    start = index[i]\n",
    "    while error[i] > thresh:\n",
    "        i += 1\n",
    "    \n",
    "    end = index[i]\n",
    "    if start != end:\n",
    "        intervals.append((start, end, np.mean(error[j: i+1])))\n",
    "        \n",
    "    i += 1\n",
    "        \n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "anomalies = pd.DataFrame(intervals, columns=['start', 'end', 'score'])\n",
    "plot(df, [anomalies, known_anomalies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters[\"epochs\"] = 100\n",
    "hyperparameters[\"shape\"] = (100, 1) # based on the window size\n",
    "hyperparameters[\"optimizer\"] = \"keras.optimizers.Adam\"\n",
    "hyperparameters[\"learning_rate\"] = 0.0005\n",
    "hyperparameters[\"latent_dim\"] = 20\n",
    "hyperparameters[\"batch_size\"] = 64\n",
    "\n",
    "# 0-1 scaling -> change activation function of output layers to sigmoid (default: tanh)\n",
    "hyperparameters['layers_generator'][7]['parameters']['activation'] = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recons_error_plot(y, y_hat, save_name) :\n",
    "    # pair-wise error calculation\n",
    "    error = np.zeros(shape=y.shape)\n",
    "    length = y.shape[0]\n",
    "    for i in range(length):\n",
    "        error[i] = abs(y_hat[i] - y[i])\n",
    "\n",
    "    # visualize the error curve\n",
    "    fig = plt.figure(figsize=(30, 3))\n",
    "    plt.plot(error)\n",
    "    plt.savefig('{}.png'.format(save_name), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orion.evaluation.contextual import contextual_accuracy, contextual_f1_score\n",
    "from orion.primitives.tadgan import score_anomalies\n",
    "import pandas as pd\n",
    "\n",
    "for idx in range(1, 20) :\n",
    "    tadgan = TadGAN(**hyperparameters)\n",
    "    tadgan.fit(X)\n",
    "    # reconstruct\n",
    "    X_hat, critic = tadgan.predict(X)\n",
    "\n",
    "    # visualize X_hat\n",
    "    plot_rws(X_hat, save_opt= True, save_name = plt_save_path+\"x_hat_plot_rws_{}\".format(idx))\n",
    "    # flatten the predicted windows\n",
    "    y_hat = unroll_ts(X_hat)\n",
    "\n",
    "    # plot the time series\n",
    "    plot_ts([y, y_hat], labels=['original', 'reconstructed'], save_opt= True, save_name = plt_save_path+\"plot_ts_{}\".format(idx))\n",
    "    recons_error_plot(y, y_hat, save_name = plt_save_path+\"recons_error_{}\".format(idx))\n",
    "\n",
    "    error, true_index, true, pred = score_anomalies(X, X_hat, critic, X_index, rec_error_type=\"dtw\", comb=\"mult\")\n",
    "    pred = np.array(pred).mean(axis=2)\n",
    "\n",
    "    # visualize the error curve\n",
    "    plot_error([[true, pred], error], save_opt= True, save_name = plt_save_path+\"plot_error_{}\".format(idx))\n",
    "\n",
    "    # threshold\n",
    "    thresh = 10\n",
    "\n",
    "    intervals = list()\n",
    "\n",
    "    i = 0\n",
    "    max_start = len(error)\n",
    "    while i < max_start:\n",
    "        j = i\n",
    "        start = index[i]\n",
    "        while error[i] > thresh:\n",
    "            i += 1\n",
    "\n",
    "        end = index[i]\n",
    "        if start != end:\n",
    "            intervals.append((start, end, np.mean(error[j: i+1])))\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    anomalies = pd.DataFrame(intervals, columns=['start', 'end', 'score'])\n",
    "    ground_truth = load_anomalies(signal)\n",
    "    accuracy = contextual_accuracy(ground_truth, anomalies, start=start, end=end)\n",
    "    f1_score = contextual_f1_score(ground_truth, anomalies, start=start, end=end)\n",
    "    plot(df, [anomalies, known_anomalies], save_opt= True, save_name = plt_save_path+\"plot_{}\".format(idx), acc = accuracy, f1=f1_score)\n",
    "    anomalies.to_csv(plt_save_path + \"anomalies_{}.csv\".format(idx), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 참고: https://ichi.pro/ko/sigyeyeol-isang-tamji-dib-leoning-sidae-264035144704586"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
